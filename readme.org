#+TITLE: soal_playground

This file is authored in org-mode markup, and it is better viewed [[https://github.com/NightMachinary/soal_playground/raw/master/readme.org][raw]] than the default Github rendering view.

* project todos
** periphal
*** @toread
**** Murphy, K. P. (2022). Probabilistic Machine Learning: An Introduction. MIT Press.
***** chapter 21 (clustering)

*** preprocessing
**** dimension reduction
#+begin_quote
In very high-dimensional spaces, Euclidean distances tend to become inflated (this is an instance of the so-called “curse of dimensionality”). Running a dimensionality reduction algorithm such as Principal component analysis (PCA) prior to k-means clustering can alleviate this problem and speed up the computations.
#+end_quote

***** UMAP
****** Is UMAP good for this purpose? I have heard it's more suited for visualizations, not analysis.

***** PCA

** phase I
*** [[./data/datasets.org][Find good datasets.]]

*** benchmark a clustering algorithm (e.g., k-means) on:
**** scalability
***** feature size (10k needed)

**** time

**** memory

**** parallelism on CPUs

**** GPU/TPU support

**** How much can it saturate the computing device?

**** correctness
***** internal clustering metrics?

***** completeness score

***** homogeneity score

**** flexibility of the implementation
***** hyperparameters

*** Find other clustering algorithms and repeat.
