#+TITLE: soal_playground

This file is authored in org-mode markup, and it is better viewed [[https://github.com/NightMachinary/soal_playground/raw/master/readme.org][raw]] than the default Github rendering view.

* project todos
** periphal
*** Save the generated datasets in =run_one.py= to avoid the upstream memory issues.

*** DONE @upstreamBug Jupyter memory leak
**** [[https://colab.research.google.com/drive/1UpqpMbb6fpCZFDXNZ-Q5i72aAqn8R2cI?usp=sharing][reproduction steps]]

**** [[https://github.com/ipython/ipython/issues/3452#thread-subscription-status][ipython/ipython#3452 Memory leak even when cache_size = 0 and history_length = 0 or history_length = 1]]

*** @toread
**** Murphy, K. P. (2022). Probabilistic Machine Learning: An Introduction. MIT Press.
***** chapter 21 (clustering)

*** preprocessing
**** [[file:./dimension reduction.org]]

**** normalization
#+begin_example python
from sklearn import pipeline
from sklearn.preprocessing import MinMaxScaler, Normalizer
from sklearn.model_selection import train_test_split

from sklearn.datasets import load_breast_cancer
X, y = load_breast_cancer(return_X_y=True)

data_train, data_test, targets_train, targets_test = train_test_split(X, y, random_state=17)

mm = pipeline.make_pipeline(MinMaxScaler(), Normalizer())
data_train = mm.fit_transform(data_train)
#+end_example

*** @? sparsity support

** phase I
*** [[./data/datasets.org][Find good datasets.]]

*** benchmark a clustering algorithm (e.g., k-means) on:
**** scalability
***** feature size (10k needed)
#+begin_quote

کلا داده تا حد چند 100 گیگ و زیر یک ترا مرز است
ولی این میتواند ضرب بعد در تعداد هم فرض شود

#+end_quote

#+begin_src bsh.dash :results verbatim :exports both :wrap results
ec $((10**(4+6)*8)) | numfmt-bytes
#: float64 is 8 bytes
#+end_src

#+RESULTS:
#+begin_results
75GiB
#+end_results

**** time

**** memory

**** parallelism on CPUs

**** GPU/TPU support

**** How much can it saturate the computing device?

**** correctness
***** internal clustering metrics?

***** completeness score

***** homogeneity score

**** flexibility of the implementation
***** hyperparameters

*** Find other clustering algorithms and repeat.
**** DBSCAN
***** HDBSCAN (expected to be the best algorithm for the job)
****** [[https://github.com/scikit-learn-contrib/hdbscan/issues/521][scikit-learn-contrib/hdbscan#521 Does HDBSCAN support out-of-core (incremental) training?]]

**** spectral clustering

**** gaussian mixture model (GMM)
***** Since we already have k-means, are GMMs useful?

**** @? latent lirichlet allocation (LDA)

**** @? power iteration clustering (PIC)
