#+TITLE: data/datasets

* sources
** UCI clustering datasets
*** [[https://archive.ics.uci.edu/ml/datasets.php?format=&task=clu&att=&area=&numAtt=&numIns=&type=&sort=nameUp&view=table][UCI Machine Learning Repository: Data Sets]]

** [[https://www.kaggle.com/datasets?tags=13304-Clustering][kaggle]]

* high-dimensional
** @good
*** @size/300MB [[https://archive.ics.uci.edu/ml/datasets/Repeat+Consumption+Matrices][UCI Machine Learning Repository: Repeat Consumption Matrices Data Set]]

** @bad
:PROPERTIES:
:visibility: folded
:END:
*** @size/3MB [[https://archive.ics.uci.edu/ml/datasets/Health+News+in+Twitter#][UCI Machine Learning Repository: Health News in Twitter Data Set]]
#+begin_quote
Each file is related to one Twitter account of a news agency. For example, bbchealth.txt is related to BBC health news. Each line contains tweet id|date and time|tweet. The separator is '|'. This text data has been used to evaluate the performance of topic models on short text data. However, it can be used for other tasks such as clustering.
#+end_quote

#+begin_example
585978391360221184|Thu Apr 09 01:31:50 +0000 2015|Breast cancer risk test devised http://bbc.in/1CimpJF
585947808772960257|Wed Apr 08 23:30:18 +0000 2015|GP workload harming care - BMA poll http://bbc.in/1ChTBRv
585947807816650752|Wed Apr 08 23:30:18 +0000 2015|Short people's 'heart risk greater' http://bbc.in/1ChTANp
#+end_example

** @mediocre
*** @size/2GB/compressed [[https://archive.ics.uci.edu/ml/datasets/Bag+of+Words][UCI Machine Learning Repository: Bag of Words Data Set]]
#+begin_example zsh
lftp -c 'mirror' '--verbose=3' 'https://archive.ics.uci.edu/ml/machine-learning-databases/bag-of
-words/'
#+end_example

- The files have differing vocabularies.

- Loading the data is itself a challenge.

#+begin_quote
The format of the docword.*.txt file is 3 header lines, followed by
NNZ triples:
---
D
W
NNZ
docID wordID count
...
docID wordID count
---

The format of the vocab.*.txt file is line contains wordID=n.
#+end_quote

** image classification
*** [[https://www.kaggle.com/nih-chest-xrays/data][NIH Chest X-rays]]

*** [[https://www.kaggle.com/c/herbarium-2021-fgvc8/data][Herbarium 2021]]
#+begin_quote
The training and test set contain images of herbarium specimens from nearly 65,000 species of vascular plants. Each image contains exactly one specimen. The text labels on the specimen images have been blurred to remove category information in the image.

Each image has different image dimensions, with a maximum of 1000 pixels in the larger dimension. These have been resized from the original image resolution. All images are in JPEG format.
#+end_quote

**** @great? [[https://www.kaggle.com/luigisaetta/herb2021-256][preprocessed of the above]]

* low-dimensional
** @good
*** [[https://code.google.com/archive/p/word2vec/][Google Code Archive - Long-term storage for Google Code Project Hosting.]]
#+begin_quote
We are publishing pre-trained vectors trained on part of Google News dataset (about 100 billion words). The model contains 300-dimensional vectors for 3 million words and phrases.

https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing
#+end_quote
