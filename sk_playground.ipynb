{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sk_playground.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO0EJeGphTFBjWn330jDi9N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NightMachinary/soal_playground/blob/master/sk_playground.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "metadata": {
        "id": "2mwPOWLFjGB8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "beea2ea5-a7f7-476b-cb85-343a4f3ba1c3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tvs0BM0MmuS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from notebook.services.config import ConfigManager\n",
        "c = ConfigManager()\n",
        "c.update('notebook', {\"CodeCell\": {\"cm_config\": {\"lineNumbers\": False, \"lineWrapping\": True}}})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "PHRgm-mqkC--",
        "outputId": "0dce6675-76fd-493c-fde1-e404b3761e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'CodeCell': {'cm_config': {'lineNumbers': False, 'lineWrapping': True}}}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# bootstrap"
      ],
      "metadata": {
        "id": "IM-YSuEGTFe8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas\n",
        "pd = pandas\n",
        "from time import time, sleep\n",
        "import concurrent\n",
        "import gc"
      ],
      "metadata": {
        "id": "x0_rkJ36UsxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! apt install -y unzip aria2 ncdu htop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0jFsBdw2iAu",
        "outputId": "b897bbe5-4f57-4235-891e-f4d2fb103fb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "htop is already the newest version (2.1.0-3).\n",
            "aria2 is already the newest version (1.33.1-1).\n",
            "ncdu is already the newest version (1.12-1).\n",
            "unzip is already the newest version (6.0-21ubuntu1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0JAAwaSXpBzd",
        "outputId": "2f2b6e63-a309-49fc-dfab-ae9c22691c50"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: fastai in /usr/local/lib/python3.7/dist-packages (2.5.3)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.7/dist-packages (from fastai) (2.2.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai) (3.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai) (21.3)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai) (0.11.1+cu111)\n",
            "Requirement already satisfied: torch<1.11,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.10.0+cu111)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai) (2.23.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai) (3.13)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from fastai) (0.0.5)\n",
            "Requirement already satisfied: pillow>6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (7.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai) (1.1.5)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.0.0)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai) (21.1.3)\n",
            "Requirement already satisfied: fastcore<1.4,>=1.3.22 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.3.27)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (4.62.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (3.0.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.6)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (57.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (0.9.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (2.0.6)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<4->fastai) (4.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<4->fastai) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<4->fastai) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (1.24.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (1.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->fastai) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai) (2018.9)\n",
            "Requirement already satisfied: skorch in /usr/local/lib/python3.7/dist-packages (0.11.0)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.7/dist-packages (from skorch) (4.62.3)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.4.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from skorch) (0.8.9)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->skorch) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->skorch) (3.0.0)\n",
            "Requirement already satisfied: memory_profiler in /usr/local/lib/python3.7/dist-packages (0.60.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from memory_profiler) (5.4.8)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install -U scikit-learn fastai \n",
        "!pip3 install -U skorch\n",
        "!pip install -U memory_profiler\n",
        "# scikit-neuralnetwork"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext memory_profiler\n",
        "\n",
        "# from memory_profiler import profile\n",
        "#: did not work on IPython\n",
        "\n",
        "import memory_profiler as mp"
      ],
      "metadata": {
        "id": "FLY-STd83hwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets"
      ],
      "metadata": {
        "id": "qSU-zEHiqFKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.torch_core import show_image, show_images"
      ],
      "metadata": {
        "id": "8x2-1qhGtfp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "CCQfrh4r8KiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn import metrics\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "#: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "#: https://scikit-learn.org/0.16/modules/generated/sklearn.cross_validation.train_test_split.html\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "#: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n",
        "\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "1JYv0UpD1Za2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# digits dataset"
      ],
      "metadata": {
        "id": "Ctl5KzABS8GR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris = datasets.load_iris()\n",
        "iris"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8r8udutxqPnV",
        "outputId": "f534835b-dbba-4298-a77d-430511c647c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
              " 'data': array([[5.1, 3.5, 1.4, 0.2],\n",
              "        [4.9, 3. , 1.4, 0.2],\n",
              "        [4.7, 3.2, 1.3, 0.2],\n",
              "        [4.6, 3.1, 1.5, 0.2],\n",
              "        [5. , 3.6, 1.4, 0.2],\n",
              "        [5.4, 3.9, 1.7, 0.4],\n",
              "        [4.6, 3.4, 1.4, 0.3],\n",
              "        [5. , 3.4, 1.5, 0.2],\n",
              "        [4.4, 2.9, 1.4, 0.2],\n",
              "        [4.9, 3.1, 1.5, 0.1],\n",
              "        [5.4, 3.7, 1.5, 0.2],\n",
              "        [4.8, 3.4, 1.6, 0.2],\n",
              "        [4.8, 3. , 1.4, 0.1],\n",
              "        [4.3, 3. , 1.1, 0.1],\n",
              "        [5.8, 4. , 1.2, 0.2],\n",
              "        [5.7, 4.4, 1.5, 0.4],\n",
              "        [5.4, 3.9, 1.3, 0.4],\n",
              "        [5.1, 3.5, 1.4, 0.3],\n",
              "        [5.7, 3.8, 1.7, 0.3],\n",
              "        [5.1, 3.8, 1.5, 0.3],\n",
              "        [5.4, 3.4, 1.7, 0.2],\n",
              "        [5.1, 3.7, 1.5, 0.4],\n",
              "        [4.6, 3.6, 1. , 0.2],\n",
              "        [5.1, 3.3, 1.7, 0.5],\n",
              "        [4.8, 3.4, 1.9, 0.2],\n",
              "        [5. , 3. , 1.6, 0.2],\n",
              "        [5. , 3.4, 1.6, 0.4],\n",
              "        [5.2, 3.5, 1.5, 0.2],\n",
              "        [5.2, 3.4, 1.4, 0.2],\n",
              "        [4.7, 3.2, 1.6, 0.2],\n",
              "        [4.8, 3.1, 1.6, 0.2],\n",
              "        [5.4, 3.4, 1.5, 0.4],\n",
              "        [5.2, 4.1, 1.5, 0.1],\n",
              "        [5.5, 4.2, 1.4, 0.2],\n",
              "        [4.9, 3.1, 1.5, 0.2],\n",
              "        [5. , 3.2, 1.2, 0.2],\n",
              "        [5.5, 3.5, 1.3, 0.2],\n",
              "        [4.9, 3.6, 1.4, 0.1],\n",
              "        [4.4, 3. , 1.3, 0.2],\n",
              "        [5.1, 3.4, 1.5, 0.2],\n",
              "        [5. , 3.5, 1.3, 0.3],\n",
              "        [4.5, 2.3, 1.3, 0.3],\n",
              "        [4.4, 3.2, 1.3, 0.2],\n",
              "        [5. , 3.5, 1.6, 0.6],\n",
              "        [5.1, 3.8, 1.9, 0.4],\n",
              "        [4.8, 3. , 1.4, 0.3],\n",
              "        [5.1, 3.8, 1.6, 0.2],\n",
              "        [4.6, 3.2, 1.4, 0.2],\n",
              "        [5.3, 3.7, 1.5, 0.2],\n",
              "        [5. , 3.3, 1.4, 0.2],\n",
              "        [7. , 3.2, 4.7, 1.4],\n",
              "        [6.4, 3.2, 4.5, 1.5],\n",
              "        [6.9, 3.1, 4.9, 1.5],\n",
              "        [5.5, 2.3, 4. , 1.3],\n",
              "        [6.5, 2.8, 4.6, 1.5],\n",
              "        [5.7, 2.8, 4.5, 1.3],\n",
              "        [6.3, 3.3, 4.7, 1.6],\n",
              "        [4.9, 2.4, 3.3, 1. ],\n",
              "        [6.6, 2.9, 4.6, 1.3],\n",
              "        [5.2, 2.7, 3.9, 1.4],\n",
              "        [5. , 2. , 3.5, 1. ],\n",
              "        [5.9, 3. , 4.2, 1.5],\n",
              "        [6. , 2.2, 4. , 1. ],\n",
              "        [6.1, 2.9, 4.7, 1.4],\n",
              "        [5.6, 2.9, 3.6, 1.3],\n",
              "        [6.7, 3.1, 4.4, 1.4],\n",
              "        [5.6, 3. , 4.5, 1.5],\n",
              "        [5.8, 2.7, 4.1, 1. ],\n",
              "        [6.2, 2.2, 4.5, 1.5],\n",
              "        [5.6, 2.5, 3.9, 1.1],\n",
              "        [5.9, 3.2, 4.8, 1.8],\n",
              "        [6.1, 2.8, 4. , 1.3],\n",
              "        [6.3, 2.5, 4.9, 1.5],\n",
              "        [6.1, 2.8, 4.7, 1.2],\n",
              "        [6.4, 2.9, 4.3, 1.3],\n",
              "        [6.6, 3. , 4.4, 1.4],\n",
              "        [6.8, 2.8, 4.8, 1.4],\n",
              "        [6.7, 3. , 5. , 1.7],\n",
              "        [6. , 2.9, 4.5, 1.5],\n",
              "        [5.7, 2.6, 3.5, 1. ],\n",
              "        [5.5, 2.4, 3.8, 1.1],\n",
              "        [5.5, 2.4, 3.7, 1. ],\n",
              "        [5.8, 2.7, 3.9, 1.2],\n",
              "        [6. , 2.7, 5.1, 1.6],\n",
              "        [5.4, 3. , 4.5, 1.5],\n",
              "        [6. , 3.4, 4.5, 1.6],\n",
              "        [6.7, 3.1, 4.7, 1.5],\n",
              "        [6.3, 2.3, 4.4, 1.3],\n",
              "        [5.6, 3. , 4.1, 1.3],\n",
              "        [5.5, 2.5, 4. , 1.3],\n",
              "        [5.5, 2.6, 4.4, 1.2],\n",
              "        [6.1, 3. , 4.6, 1.4],\n",
              "        [5.8, 2.6, 4. , 1.2],\n",
              "        [5. , 2.3, 3.3, 1. ],\n",
              "        [5.6, 2.7, 4.2, 1.3],\n",
              "        [5.7, 3. , 4.2, 1.2],\n",
              "        [5.7, 2.9, 4.2, 1.3],\n",
              "        [6.2, 2.9, 4.3, 1.3],\n",
              "        [5.1, 2.5, 3. , 1.1],\n",
              "        [5.7, 2.8, 4.1, 1.3],\n",
              "        [6.3, 3.3, 6. , 2.5],\n",
              "        [5.8, 2.7, 5.1, 1.9],\n",
              "        [7.1, 3. , 5.9, 2.1],\n",
              "        [6.3, 2.9, 5.6, 1.8],\n",
              "        [6.5, 3. , 5.8, 2.2],\n",
              "        [7.6, 3. , 6.6, 2.1],\n",
              "        [4.9, 2.5, 4.5, 1.7],\n",
              "        [7.3, 2.9, 6.3, 1.8],\n",
              "        [6.7, 2.5, 5.8, 1.8],\n",
              "        [7.2, 3.6, 6.1, 2.5],\n",
              "        [6.5, 3.2, 5.1, 2. ],\n",
              "        [6.4, 2.7, 5.3, 1.9],\n",
              "        [6.8, 3. , 5.5, 2.1],\n",
              "        [5.7, 2.5, 5. , 2. ],\n",
              "        [5.8, 2.8, 5.1, 2.4],\n",
              "        [6.4, 3.2, 5.3, 2.3],\n",
              "        [6.5, 3. , 5.5, 1.8],\n",
              "        [7.7, 3.8, 6.7, 2.2],\n",
              "        [7.7, 2.6, 6.9, 2.3],\n",
              "        [6. , 2.2, 5. , 1.5],\n",
              "        [6.9, 3.2, 5.7, 2.3],\n",
              "        [5.6, 2.8, 4.9, 2. ],\n",
              "        [7.7, 2.8, 6.7, 2. ],\n",
              "        [6.3, 2.7, 4.9, 1.8],\n",
              "        [6.7, 3.3, 5.7, 2.1],\n",
              "        [7.2, 3.2, 6. , 1.8],\n",
              "        [6.2, 2.8, 4.8, 1.8],\n",
              "        [6.1, 3. , 4.9, 1.8],\n",
              "        [6.4, 2.8, 5.6, 2.1],\n",
              "        [7.2, 3. , 5.8, 1.6],\n",
              "        [7.4, 2.8, 6.1, 1.9],\n",
              "        [7.9, 3.8, 6.4, 2. ],\n",
              "        [6.4, 2.8, 5.6, 2.2],\n",
              "        [6.3, 2.8, 5.1, 1.5],\n",
              "        [6.1, 2.6, 5.6, 1.4],\n",
              "        [7.7, 3. , 6.1, 2.3],\n",
              "        [6.3, 3.4, 5.6, 2.4],\n",
              "        [6.4, 3.1, 5.5, 1.8],\n",
              "        [6. , 3. , 4.8, 1.8],\n",
              "        [6.9, 3.1, 5.4, 2.1],\n",
              "        [6.7, 3.1, 5.6, 2.4],\n",
              "        [6.9, 3.1, 5.1, 2.3],\n",
              "        [5.8, 2.7, 5.1, 1.9],\n",
              "        [6.8, 3.2, 5.9, 2.3],\n",
              "        [6.7, 3.3, 5.7, 2.5],\n",
              "        [6.7, 3. , 5.2, 2.3],\n",
              "        [6.3, 2.5, 5. , 1.9],\n",
              "        [6.5, 3. , 5.2, 2. ],\n",
              "        [6.2, 3.4, 5.4, 2.3],\n",
              "        [5.9, 3. , 5.1, 1.8]]),\n",
              " 'data_module': 'sklearn.datasets.data',\n",
              " 'feature_names': ['sepal length (cm)',\n",
              "  'sepal width (cm)',\n",
              "  'petal length (cm)',\n",
              "  'petal width (cm)'],\n",
              " 'filename': 'iris.csv',\n",
              " 'frame': None,\n",
              " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
              " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10')}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(iris.DESCR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRtEs5_Tqzzl",
        "outputId": "e0a7a9ab-ff01-41f5-8c47-813bddf92db9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _iris_dataset:\n",
            "\n",
            "Iris plants dataset\n",
            "--------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 150 (50 in each of three classes)\n",
            "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
            "    :Attribute Information:\n",
            "        - sepal length in cm\n",
            "        - sepal width in cm\n",
            "        - petal length in cm\n",
            "        - petal width in cm\n",
            "        - class:\n",
            "                - Iris-Setosa\n",
            "                - Iris-Versicolour\n",
            "                - Iris-Virginica\n",
            "                \n",
            "    :Summary Statistics:\n",
            "\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "                    Min  Max   Mean    SD   Class Correlation\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
            "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
            "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
            "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "    :Class Distribution: 33.3% for each of 3 classes.\n",
            "    :Creator: R.A. Fisher\n",
            "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
            "    :Date: July, 1988\n",
            "\n",
            "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
            "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
            "Machine Learning Repository, which has two wrong data points.\n",
            "\n",
            "This is perhaps the best known database to be found in the\n",
            "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
            "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
            "data set contains 3 classes of 50 instances each, where each class refers to a\n",
            "type of iris plant.  One class is linearly separable from the other 2; the\n",
            "latter are NOT linearly separable from each other.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
            "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
            "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
            "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
            "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
            "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
            "     Structure and Classification Rule for Recognition in Partially Exposed\n",
            "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
            "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
            "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
            "     on Information Theory, May 1972, 431-433.\n",
            "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
            "     conceptual clustering system finds 3 classes in the data.\n",
            "   - Many, many more ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "digits = datasets.load_digits()\n",
        "print(digits.DESCR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0pJsOklrUri",
        "outputId": "d7199fe7-c937-46aa-fffa-0ffb7c862066"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _digits_dataset:\n",
            "\n",
            "Optical recognition of handwritten digits dataset\n",
            "--------------------------------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 1797\n",
            "    :Number of Attributes: 64\n",
            "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
            "    :Missing Attribute Values: None\n",
            "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
            "    :Date: July; 1998\n",
            "\n",
            "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
            "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
            "\n",
            "The data set contains images of hand-written digits: 10 classes where\n",
            "each class refers to a digit.\n",
            "\n",
            "Preprocessing programs made available by NIST were used to extract\n",
            "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
            "total of 43 people, 30 contributed to the training set and different 13\n",
            "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
            "4x4 and the number of on pixels are counted in each block. This generates\n",
            "an input matrix of 8x8 where each element is an integer in the range\n",
            "0..16. This reduces dimensionality and gives invariance to small\n",
            "distortions.\n",
            "\n",
            "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
            "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
            "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
            "1994.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
            "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
            "    Graduate Studies in Science and Engineering, Bogazici University.\n",
            "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
            "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
            "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
            "    Electrical and Electronic Engineering Nanyang Technological University.\n",
            "    2005.\n",
            "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
            "    Algorithm. NIPS. 2000.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"digits_x: {digits.data.shape}, digits_y: {digits.target.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GriP0cnErnye",
        "outputId": "12ba26da-0d82-4033-e1d8-70abc7305d5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "digits_x: (1797, 64), digits_y: (1797,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "digits.images[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qf0WCCK-tWN7",
        "outputId": "788e5472-2fa7-4485-f53d-21c4ee54f82c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n",
              "       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n",
              "       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n",
              "       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n",
              "       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n",
              "       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n",
              "       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n",
              "       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_image(digits.images[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "qMRVemKjue4I",
        "outputId": "5ad66627-3cba-4549-ca74-669d812223cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f76e11a8110>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABECAYAAAA4E5OyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAB0ElEQVR4nO3cvUtCURzG8aNZtJhFQg0tETgEQiENQVMR1FRLeadGoVVpCIz6E9yC9ihqLSJcAyExopYanHslERoi7N7G6uE+F+9pqOH5jOfHscOXA2dQinieZ+RL9K8P8N8oCFAQoCBAQUAsaDgbXbJ6gp5zk3S2Vtj3Xd+oLdA9qfwdnbXuH9o/2Ddl9zDit64bAhQEKAhQEKAgQEFA4LNriz2txhjjxBu+66XeV7rn+OKUzjJbq3SW3KnQGaMbAhQEKAhQEKAgQEGA9bPbms7QmRO/pLP5Ocd3PXF1Q/csn83Q2cv4B50l6YTTDQEKAhQEKAhQEKAgwPrZfevnW4uPaTpzA55Xpno9EnqPLd0QoCBAQYCCAAUB9q9MH2+5W+FfZabMeei/FUu801mr2RX684LohgAFAQoCFAQoCFAQYP3sdjdcOptI1+msyQ4yOED3ZEdrdHZwMkVnNnRDgIIABQEKAhQEKAiwfnZ7btkDaszm0BGdreTyvuudi09W5xheD/8roSC6IUBBgIIABQEKAhQEWD+7QV9JZrcLdFYs7Pmul+r8V0LVsY72D/ZLuiFAQYCCAAUBCgIUBET0zxB+0g0BCgIUBCgIUBCgIOATX75J5Ol/hWkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_images(digits.images, ncols=5, nrows=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "BR6VwiYMurjg",
        "outputId": "8263eab4-db90-4fed-bb54-d40982b4c1cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x864 with 20 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVC"
      ],
      "metadata": {
        "id": "cs5jC0FC1YM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##\n",
        "# clf = SVC()\n",
        "##\n",
        "clf = KMeans(n_clusters=10, max_iter=10_000)\n",
        "##"
      ],
      "metadata": {
        "id": "fnAK6jIu1iwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##\n",
        "# train_x = digits.data[0:1000]\n",
        "# train_y = digits.target[0:1000]\n",
        "# val_x = digits.data[1000:]\n",
        "# val_y = digits.target[1000:]\n",
        "##\n",
        "train_x, val_x, train_y, val_y = \\\n",
        "train_test_split(digits.data, digits.target, test_size=0.25)\n",
        "\n",
        "# normalize the data via scaling\n",
        "t = MinMaxScaler()\n",
        "t.fit(train_x)\n",
        "train_x = t.transform(train_x)\n",
        "val_x = t.transform(val_x)\n",
        "##\n",
        "train_x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RunldO35Ajl",
        "outputId": "c50be19f-c715-4d2e-907a-9ed22c8b779c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1347, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(train_x, train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x42KB22o1xrC",
        "outputId": "63753a16-1494-4863-8c76-fef3b6634599"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(max_iter=10000, n_clusters=10)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = clf.predict(val_x)\n",
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIQuLrZ75Q1V",
        "outputId": "0503073d-1d81-4901-aa07-674578ba1e6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 7, 9, 8, 5, 7, 3, 1, 8, 3, 1, 8, 2, 8, 6, 8, 6, 8, 9, 3, 6, 1,\n",
              "       6, 2, 2, 4, 9, 0, 9, 4, 2, 9, 2, 6, 8, 3, 7, 8, 4, 6, 3, 8, 6, 8,\n",
              "       7, 8, 0, 8, 9, 1, 3, 5, 6, 6, 3, 8, 5, 4, 6, 0, 6, 5, 5, 3, 3, 0,\n",
              "       7, 7, 8, 7, 6, 8, 2, 8, 3, 2, 6, 6, 7, 4, 8, 2, 5, 7, 1, 6, 5, 8,\n",
              "       8, 9, 6, 4, 6, 0, 3, 2, 9, 6, 9, 1, 6, 5, 9, 8, 8, 0, 3, 6, 6, 5,\n",
              "       9, 0, 0, 3, 2, 9, 2, 0, 2, 9, 8, 5, 0, 0, 8, 4, 2, 5, 9, 2, 2, 6,\n",
              "       0, 7, 0, 0, 4, 2, 3, 3, 8, 1, 4, 6, 0, 1, 0, 9, 6, 6, 7, 5, 2, 8,\n",
              "       5, 3, 2, 8, 4, 9, 9, 7, 5, 0, 8, 6, 2, 5, 7, 0, 1, 4, 0, 8, 2, 6,\n",
              "       2, 3, 1, 5, 4, 9, 0, 2, 9, 1, 1, 2, 6, 6, 6, 9, 8, 8, 3, 7, 8, 3,\n",
              "       2, 9, 9, 2, 3, 7, 3, 4, 7, 3, 5, 0, 9, 0, 3, 2, 2, 4, 4, 2, 8, 9,\n",
              "       3, 4, 8, 0, 6, 6, 4, 9, 8, 3, 7, 4, 8, 1, 7, 0, 6, 3, 0, 3, 4, 8,\n",
              "       7, 7, 0, 2, 0, 3, 4, 1, 8, 9, 4, 0, 1, 4, 9, 0, 4, 0, 9, 3, 4, 0,\n",
              "       6, 1, 6, 5, 2, 4, 6, 1, 6, 6, 9, 4, 1, 4, 0, 4, 1, 4, 5, 6, 0, 8,\n",
              "       4, 2, 4, 1, 9, 0, 8, 6, 3, 1, 1, 3, 8, 3, 8, 4, 2, 0, 8, 9, 5, 4,\n",
              "       4, 7, 9, 5, 8, 6, 3, 4, 9, 5, 2, 2, 1, 2, 5, 4, 0, 3, 5, 8, 5, 2,\n",
              "       0, 1, 1, 1, 4, 3, 9, 6, 3, 5, 6, 5, 3, 8, 8, 3, 6, 3, 0, 6, 2, 4,\n",
              "       0, 6, 4, 0, 0, 1, 4, 5, 9, 4, 1, 2, 8, 3, 1, 6, 9, 6, 3, 7, 6, 1,\n",
              "       6, 2, 1, 6, 8, 9, 5, 4, 3, 4, 6, 3, 3, 3, 9, 8, 8, 1, 9, 4, 1, 5,\n",
              "       8, 3, 2, 9, 1, 0, 9, 5, 3, 7, 0, 4, 8, 0, 0, 4, 4, 8, 6, 4, 0, 8,\n",
              "       1, 8, 0, 0, 4, 8, 6, 3, 7, 6, 4, 8, 1, 1, 1, 0, 4, 1, 9, 9, 5, 9,\n",
              "       6, 7, 4, 0, 9, 3, 6, 1, 9, 6], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99BSEKqIiS5m",
        "outputId": "cd056c04-d2fc-4a9c-f503-1a8a7ffdfb1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 8, 6, 9, 4, 1, 3, 5, 9, 3, 5, 9, 7, 8, 2, 9, 2, 9, 6, 3, 2, 9,\n",
              "       1, 7, 7, 0, 6, 7, 6, 0, 7, 6, 2, 2, 9, 2, 1, 8, 0, 2, 3, 8, 2, 8,\n",
              "       1, 8, 8, 9, 6, 5, 3, 4, 2, 2, 3, 5, 4, 0, 2, 8, 2, 4, 4, 3, 3, 8,\n",
              "       1, 9, 9, 1, 2, 9, 7, 8, 3, 7, 1, 2, 8, 0, 9, 7, 4, 8, 5, 1, 4, 3,\n",
              "       9, 6, 2, 0, 2, 8, 3, 7, 6, 1, 1, 5, 2, 4, 6, 9, 8, 1, 3, 2, 2, 4,\n",
              "       6, 1, 8, 3, 9, 6, 7, 8, 7, 6, 3, 4, 8, 8, 9, 0, 7, 4, 6, 7, 7, 2,\n",
              "       1, 7, 8, 1, 0, 7, 3, 3, 9, 5, 0, 2, 8, 5, 8, 6, 2, 2, 1, 4, 7, 9,\n",
              "       4, 3, 3, 9, 0, 6, 6, 8, 4, 1, 3, 2, 7, 4, 9, 8, 7, 0, 1, 5, 7, 2,\n",
              "       9, 3, 5, 4, 0, 6, 3, 7, 6, 5, 5, 7, 2, 2, 2, 6, 8, 5, 3, 1, 8, 3,\n",
              "       7, 6, 6, 7, 3, 4, 3, 0, 1, 3, 4, 8, 6, 8, 3, 7, 7, 0, 6, 7, 9, 6,\n",
              "       3, 0, 9, 8, 2, 2, 0, 6, 9, 3, 9, 0, 9, 5, 1, 1, 2, 3, 2, 3, 0, 5,\n",
              "       1, 1, 3, 7, 8, 3, 0, 5, 9, 6, 0, 8, 5, 0, 6, 8, 0, 1, 6, 3, 0, 1,\n",
              "       2, 5, 2, 4, 7, 0, 2, 5, 2, 2, 6, 0, 5, 0, 3, 0, 5, 0, 4, 2, 2, 9,\n",
              "       0, 7, 0, 5, 6, 8, 9, 8, 3, 5, 5, 3, 8, 3, 9, 0, 7, 1, 9, 6, 4, 0,\n",
              "       0, 8, 6, 4, 9, 2, 3, 0, 6, 4, 7, 7, 5, 7, 4, 0, 8, 9, 4, 5, 4, 7,\n",
              "       8, 5, 5, 5, 0, 3, 6, 2, 3, 4, 2, 4, 3, 9, 9, 2, 2, 8, 1, 2, 7, 0,\n",
              "       8, 1, 0, 8, 1, 5, 0, 4, 6, 0, 5, 7, 9, 2, 5, 2, 6, 2, 3, 9, 2, 5,\n",
              "       2, 7, 8, 1, 9, 6, 4, 0, 3, 0, 2, 3, 3, 9, 6, 9, 8, 5, 6, 0, 5, 4,\n",
              "       9, 3, 7, 6, 5, 4, 6, 4, 3, 9, 1, 0, 9, 1, 1, 0, 0, 9, 2, 0, 8, 5,\n",
              "       5, 5, 1, 2, 0, 9, 1, 3, 9, 2, 0, 9, 9, 5, 5, 8, 0, 5, 6, 6, 4, 6,\n",
              "       2, 4, 0, 1, 6, 3, 2, 5, 6, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "permu = {\n",
        "    6: 1,\n",
        "    9: 4,\n",
        "    1: 0,\n",
        "    5: 5,\n",
        "    7: 3,\n",
        "    2: 6,\n",
        "    3: 9,\n",
        "    4: 7,\n",
        "    8: 8,\n",
        "    0: 2,\n",
        "}\n",
        "preds_permuted = [permu[p] for p in preds]\n",
        "sum(preds_permuted == val_y)/len(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JitkdSeQiaMn",
        "outputId": "ec44d8d2-0240-4895-fd82-5847f6d88919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.051111111111111114"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.completeness_score(val_y, preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDpqTWGTkgo7",
        "outputId": "e543b764-3307-474f-e9b9-29e4ce56ff77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7657406505019037"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.homogeneity_score(val_y, preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzSWQHqqn7qs",
        "outputId": "55ec7e9c-926f-48d2-d353-ee9118eeae65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7603351771923036"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(preds == val_y)/len(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1kCyksI5b5j",
        "outputId": "6d610649-b692-4aac-8d3f-9b7324acdbff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.12444444444444444"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# reddit_sample"
      ],
      "metadata": {
        "id": "ljKdywrTTrn3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## loading the data"
      ],
      "metadata": {
        "id": "ResTfCkD9MKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!aria2c --allow-overwrite=true 'https://archive.ics.uci.edu/ml/machine-learning-databases/00441/repeat_consumption_data.zip'\n",
        "!yes | unzip repeat_consumption_data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1tsr3FY-Coy",
        "outputId": "1fbf270f-1d8a-4194-c682-b4046e71d988"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "01/17 13:52:18 [\u001b[1;32mNOTICE\u001b[0m] Downloading 1 item(s)\n",
            "\u001b[0m\n",
            "01/17 13:52:23 [\u001b[1;32mNOTICE\u001b[0m] Download complete: /content/repeat_consumption_data.zip\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "1ae100|\u001b[1;32mOK\u001b[0m  |    14MiB/s|/content/repeat_consumption_data.zip\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "Archive:  repeat_consumption_data.zip\n",
            "replace data/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: data/.DS_Store          \n",
            "replace __MACOSX/data/._.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: __MACOSX/data/._.DS_Store  \n",
            "replace data/lastfm/validation.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: data/lastfm/validation.csv  \n",
            "replace data/lastfm/test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: data/lastfm/test.csv    \n",
            "replace __MACOSX/data/lastfm/._test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: __MACOSX/data/lastfm/._test.csv  \n",
            "replace data/lastfm/train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: data/lastfm/train.csv   \n",
            "replace data/reddit_sample/validation.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: data/reddit_sample/validation.csv  \n",
            "replace data/reddit_sample/test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: data/reddit_sample/test.csv  \n",
            "replace data/reddit_sample/train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: data/reddit_sample/train.csv  \n",
            "replace data/reddit_top/validation.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: data/reddit_top/validation.csv  \n",
            "replace data/reddit_top/test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: data/reddit_top/test.csv  \n",
            "replace data/reddit_top/train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: data/reddit_top/train.csv  \n",
            "replace data/tw_oc/validation.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: data/tw_oc/validation.csv  \n",
            "replace data/tw_oc/test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: data/tw_oc/test.csv     \n",
            "replace data/tw_oc/train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: data/tw_oc/train.csv    \n",
            "replace data/tw_ny/validation.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: data/tw_ny/validation.csv  \n",
            "replace data/tw_ny/test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: data/tw_ny/test.csv     \n",
            "replace data/tw_ny/train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: data/tw_ny/train.csv    \n",
            "replace data/go_sf/validation.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: data/go_sf/validation.csv  \n",
            "replace data/go_sf/test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: data/go_sf/test.csv     \n",
            "replace data/go_sf/train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: data/go_sf/train.csv    \n",
            "replace data/go_ny/validation.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: data/go_ny/validation.csv  \n",
            "replace data/go_ny/test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: data/go_ny/test.csv     \n",
            "replace data/go_ny/train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: data/go_ny/train.csv    \n",
            "replace data/readme.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: data/readme.txt         \n",
            "replace __MACOSX/data/._readme.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: __MACOSX/data/._readme.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"/content/data/reddit_sample/train.csv\""
      ],
      "metadata": {
        "id": "E0Gf8hj32LvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_load():\n",
        "  train_raw = pd.read_csv(train_path, names=['x','y','z'])\n",
        "  display(train_raw)\n",
        "\n",
        "  #: @todo1 use sparse matrices\n",
        "  train_mat = train_raw.pivot(index=\"x\", columns=\"y\", values=\"z\")\n",
        "  # display(train_mat.loc[0,741])\n",
        "  display(train_mat)\n",
        "\n",
        "\n",
        "  train_np = train_mat.to_numpy(na_value=0.)\n",
        "  return train_np #, train_mat\n",
        "\n",
        "train_np = train_load()\n",
        "display(train_np)\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-sVo_2Hz55Fd",
        "outputId": "1d037d9a-5c8d-4e60-bfac-74a6eda3bb62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-72a56a53-f617-4154-a4d5-3c80035902fd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>741</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>877</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>5773</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>6492</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>7083</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379545</th>\n",
              "      <td>20023</td>\n",
              "      <td>17045</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379546</th>\n",
              "      <td>20023</td>\n",
              "      <td>18347</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379547</th>\n",
              "      <td>20023</td>\n",
              "      <td>21204</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379548</th>\n",
              "      <td>20023</td>\n",
              "      <td>21342</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379549</th>\n",
              "      <td>20023</td>\n",
              "      <td>21385</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>379550 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72a56a53-f617-4154-a4d5-3c80035902fd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-72a56a53-f617-4154-a4d5-3c80035902fd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-72a56a53-f617-4154-a4d5-3c80035902fd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            x      y    z\n",
              "0           0    741    1\n",
              "1           0    877  189\n",
              "2           0   5773    1\n",
              "3           0   6492    3\n",
              "4           0   7083    2\n",
              "...       ...    ...  ...\n",
              "379545  20023  17045    1\n",
              "379546  20023  18347    2\n",
              "379547  20023  21204    2\n",
              "379548  20023  21342    1\n",
              "379549  20023  21385    0\n",
              "\n",
              "[379550 rows x 3 columns]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f6182162-94e6-478c-b660-5b4ea5e64a76\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>y</th>\n",
              "      <th>1</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>20</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>25</th>\n",
              "      <th>29</th>\n",
              "      <th>31</th>\n",
              "      <th>33</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>39</th>\n",
              "      <th>41</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>56</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>...</th>\n",
              "      <th>21331</th>\n",
              "      <th>21333</th>\n",
              "      <th>21334</th>\n",
              "      <th>21335</th>\n",
              "      <th>21338</th>\n",
              "      <th>21340</th>\n",
              "      <th>21341</th>\n",
              "      <th>21342</th>\n",
              "      <th>21344</th>\n",
              "      <th>21345</th>\n",
              "      <th>21346</th>\n",
              "      <th>21347</th>\n",
              "      <th>21349</th>\n",
              "      <th>21351</th>\n",
              "      <th>21352</th>\n",
              "      <th>21353</th>\n",
              "      <th>21354</th>\n",
              "      <th>21355</th>\n",
              "      <th>21356</th>\n",
              "      <th>21358</th>\n",
              "      <th>21359</th>\n",
              "      <th>21360</th>\n",
              "      <th>21361</th>\n",
              "      <th>21362</th>\n",
              "      <th>21363</th>\n",
              "      <th>21365</th>\n",
              "      <th>21367</th>\n",
              "      <th>21368</th>\n",
              "      <th>21371</th>\n",
              "      <th>21372</th>\n",
              "      <th>21373</th>\n",
              "      <th>21374</th>\n",
              "      <th>21375</th>\n",
              "      <th>21376</th>\n",
              "      <th>21377</th>\n",
              "      <th>21378</th>\n",
              "      <th>21381</th>\n",
              "      <th>21382</th>\n",
              "      <th>21383</th>\n",
              "      <th>21385</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20019</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20020</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20021</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20022</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20023</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20024 rows × 13456 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6182162-94e6-478c-b660-5b4ea5e64a76')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f6182162-94e6-478c-b660-5b4ea5e64a76 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f6182162-94e6-478c-b660-5b4ea5e64a76');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "y      1      3      4      5      6      ...  21378  21381  21382  21383  21385\n",
              "x                                         ...                                   \n",
              "0        NaN    NaN    NaN    NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN\n",
              "1        NaN    NaN    NaN    NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN\n",
              "2        NaN    NaN    NaN    NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN\n",
              "3        NaN    NaN    NaN    NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN\n",
              "4        NaN    NaN    NaN    NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN\n",
              "...      ...    ...    ...    ...    ...  ...    ...    ...    ...    ...    ...\n",
              "20019    NaN    NaN    NaN    NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN\n",
              "20020    NaN    NaN    NaN    NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN\n",
              "20021    NaN    NaN    NaN    NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN\n",
              "20022    NaN    NaN    NaN    NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN\n",
              "20023    NaN    NaN    NaN    NaN    NaN  ...    NaN    NaN    NaN    NaN    0.0\n",
              "\n",
              "[20024 rows x 13456 columns]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_np.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1Ypm8zW9ny6",
        "outputId": "e9af03d0-115a-47f7-8633-f3319ea7d2e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20024, 13456)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_np[0][[train_np[0] != 0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74In2i5w8yYh",
        "outputId": "fb5fa0c6-6aad-4638-8cf2-079b55bbc6fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  1., 189.,   1.,   3.,   2.,  22.,   2.,   5.,   4.,   8.,   1.,\n",
              "         3.,   1.,   2.,   1.,  10.,   1.,   3.])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## benchmarking tools"
      ],
      "metadata": {
        "id": "KT48bi4r9PAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def benchmark_one(proc, *, name, interval=1):\n",
        "  mp_kwargs = { \n",
        "    \"max_usage\": True, \n",
        "    \"retval\": True,\n",
        "    # \"timeout\": timeout, #: after reading its source code, this basically only manipulates the number of iterations\n",
        "    \"max_iterations\": 1,\n",
        "    # \"multiprocess\": True, #: useless for functions\n",
        "    # \"include_children\": True, \n",
        "    #: @upstreamBug? This double counts (well, probably a copy-on-write fork causes this) memory when measuring functions, but not when measuring the starting memory\n",
        "    \"include_children\": False,\n",
        "    \"interval\": interval  \n",
        "  }\n",
        "  start_mem = mp.memory_usage(**mp_kwargs)\n",
        "  start_time = time()\n",
        "  res = mp.memory_usage(proc, **mp_kwargs)\n",
        "  end_time = time()\n",
        "  dur = end_time - start_time\n",
        "  ret_val = res[1]\n",
        "  max_mem = res[0] #: I don't know why this is not returning the number of samples per its doc.\n",
        "  used_mem = max_mem - start_mem\n",
        "\n",
        "  print(f\"{name}: dur={dur}, used_mem={used_mem}, max_mem={max_mem}\")\n",
        "  # print(f\"res={repr(res)}\")\n",
        "\n",
        "  return ret_val, dur, used_mem\n",
        "\n",
        "def benchmark_n(n, *args, **kwargs):\n",
        "  \"Even with forking, the amount of memory used is dependent on the state of the process before the fork; e.g., the more memory it has claimed from the OS and then subsequently freed but not released back, can decrease its further OS memory usage.\"\n",
        "  \n",
        "  fork_p = True\n",
        "\n",
        "  durs = np.empty(n) #: filled with nans\n",
        "  used_mems = np.empty(n)\n",
        "  losses = np.empty(n)\n",
        "  ret_val = None #: needed for correct scoping\n",
        "  for i in range(n):\n",
        "    if fork_p == True:\n",
        "      with concurrent.futures.ProcessPoolExecutor(max_workers=1) as executor:\n",
        "        res = executor.submit(benchmark_one, *args, **kwargs).result()\n",
        "    else:\n",
        "      res = benchmark_one(*args, **kwargs)\n",
        "    \n",
        "    ret_val, dur, used_mem = res\n",
        "    \n",
        "    loss = ret_val['loss']\n",
        "    losses[i] = loss\n",
        "    durs[i] = dur\n",
        "    used_mems[i] = used_mem\n",
        "    if 1 != (n-1):\n",
        "      ret_val = None #: might help GC\n",
        "\n",
        "  return (ret_val, durs, used_mems, losses)"
      ],
      "metadata": {
        "id": "hmz0ib9K3Ymq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dummy():\n",
        "  gc.collect()\n",
        "  sleep(1)\n",
        "  a = np.zeros(100_000_000)\n",
        "  sleep(1.1)\n",
        "  return {'loss': 0}\n",
        "\n",
        "def nop():\n",
        "  return None\n",
        "\n",
        "benchmark_n(3, \n",
        "              (dummy, []), \n",
        "              name=\"dummy\",)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Vvi6wolNBXZ",
        "outputId": "166ae659-f35a-4f36-ad00-871f93b041a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dummy: dur=3.5496842861175537, used_mem=513.10546875, max_mem=5593.1328125\n",
            "dummy: dur=3.565230131149292, used_mem=513.30859375, max_mem=5593.2109375\n",
            "dummy: dur=3.537529945373535, used_mem=513.16015625, max_mem=5593.1875\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None,\n",
              " array([3.54968429, 3.56523013, 3.53752995]),\n",
              " array([513.10546875, 513.30859375, 513.16015625]),\n",
              " array([0., 0., 0.]))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### tmp"
      ],
      "metadata": {
        "id": "X3jzGwaOtJ09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from resource import getrusage, RUSAGE_SELF\n",
        "getrusage(RUSAGE_SELF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "-SrDDs-Ds9yC",
        "outputId": "0776d183-3289-421b-c093-bbb3ec39c728"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "resource.struct_rusage(ru_utime=27.085694, ru_stime=29.27901, ru_maxrss=14173152, ru_ixrss=0, ru_idrss=0, ru_isrss=0, ru_minflt=3447033, ru_majflt=12, ru_nswap=0, ru_inblock=2928, ru_oublock=24, ru_msgsnd=0, ru_msgrcv=0, ru_nsignals=0, ru_nvcsw=123288, ru_nivcsw=11229)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## k-means"
      ],
      "metadata": {
        "id": "qUd7UmbUg9aI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def kmeans_sklearn_n10_iter10(input_data):\n",
        "  clf = KMeans(n_clusters=10, max_iter=10)\n",
        "  clf.fit(input_data)\n",
        "  return {'loss': clf.inertia_}\n",
        "\n",
        "def kmeans_sklearn_n10_iter10_withdata():\n",
        "  return kmeans_sklearn_n10_iter10(train_np)\n",
        "\n",
        "ret_val, durs, used_mems, losses = \\\n",
        "  (benchmark_n(3, \n",
        "              (kmeans_sklearn_n10_iter10_withdata, []), \n",
        "              # ((lambda: kmeans_sklearn_n10_iter10(train_np)), []), \n",
        "              # (kmeans_sklearn_n10_iter10, [train_np]), \n",
        "              name=\"kmeans_sklearn_n10_iter10\",))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "JK-qsqRq5GFu",
        "outputId": "0cefe5bd-837a-4ac3-a6c3-6b3c36643cb4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kmeans_sklearn_n10_iter10: dur=63.25836634635925, used_mem=10.25390625, max_mem=13066.75390625\n",
            "kmeans_sklearn_n10_iter10: dur=63.773088693618774, used_mem=10.31640625, max_mem=13066.75390625\n",
            "kmeans_sklearn_n10_iter10: dur=62.86378312110901, used_mem=10.31640625, max_mem=13066.75390625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### interactive"
      ],
      "metadata": {
        "id": "mtR8Q5UnrDnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_pred = clf.predict(train_np)\n",
        "train_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bF309v-B-7ye",
        "outputId": "768ed630-ef88-42e0-a3ca-292c442c22cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0, 68, 68, ..., 68, 68, 68], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_pred_pd = pd.Series(train_pred)\n",
        "train_pred_pd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v523c4-Q_T2Z",
        "outputId": "deb6fc83-ce93-488d-95e1-9621ea2751c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         0\n",
              "1        68\n",
              "2        68\n",
              "3        68\n",
              "4        68\n",
              "         ..\n",
              "20019    68\n",
              "20020    68\n",
              "20021    68\n",
              "20022    68\n",
              "20023    68\n",
              "Length: 20024, dtype: int32"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
        "  print(train_pred_pd.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QPIE4o7_4o8",
        "outputId": "faa45413-c48e-4ede-8a45-a9b0c229cdd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68    18435\n",
            "0       905\n",
            "75      149\n",
            "16       80\n",
            "61       73\n",
            "82       45\n",
            "19       38\n",
            "21       35\n",
            "88       23\n",
            "20       17\n",
            "27       16\n",
            "58       16\n",
            "35       10\n",
            "25       10\n",
            "84        9\n",
            "43        9\n",
            "22        8\n",
            "86        7\n",
            "79        6\n",
            "89        6\n",
            "49        5\n",
            "66        5\n",
            "67        4\n",
            "81        4\n",
            "76        4\n",
            "57        4\n",
            "7         4\n",
            "40        3\n",
            "87        3\n",
            "33        3\n",
            "2         3\n",
            "13        3\n",
            "28        3\n",
            "92        3\n",
            "6         2\n",
            "90        2\n",
            "65        2\n",
            "72        2\n",
            "10        2\n",
            "44        2\n",
            "73        2\n",
            "38        2\n",
            "80        2\n",
            "3         2\n",
            "36        1\n",
            "5         1\n",
            "4         1\n",
            "52        1\n",
            "32        1\n",
            "1         1\n",
            "99        1\n",
            "83        1\n",
            "51        1\n",
            "17        1\n",
            "48        1\n",
            "37        1\n",
            "64        1\n",
            "50        1\n",
            "34        1\n",
            "18        1\n",
            "97        1\n",
            "96        1\n",
            "98        1\n",
            "95        1\n",
            "53        1\n",
            "69        1\n",
            "60        1\n",
            "29        1\n",
            "45        1\n",
            "77        1\n",
            "93        1\n",
            "14        1\n",
            "30        1\n",
            "46        1\n",
            "62        1\n",
            "78        1\n",
            "94        1\n",
            "15        1\n",
            "31        1\n",
            "47        1\n",
            "63        1\n",
            "12        1\n",
            "91        1\n",
            "59        1\n",
            "8         1\n",
            "85        1\n",
            "54        1\n",
            "70        1\n",
            "23        1\n",
            "39        1\n",
            "71        1\n",
            "24        1\n",
            "11        1\n",
            "56        1\n",
            "9         1\n",
            "41        1\n",
            "26        1\n",
            "42        1\n",
            "74        1\n",
            "55        1\n",
            "dtype: int64\n"
          ]
        }
      ]
    }
  ]
}