{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sk_playground.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPwpAGoSSlaM+/h2TG0xlXF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NightMachinary/soal_playground/blob/master/sk_playground.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas\n",
        "pd = pandas"
      ],
      "metadata": {
        "id": "x0_rkJ36UsxP"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! apt install -y unzip aria2 ncdu htop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0jFsBdw2iAu",
        "outputId": "911ab68b-9fad-4360-97e0-2f257960713f"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "htop is already the newest version (2.1.0-3).\n",
            "aria2 is already the newest version (1.33.1-1).\n",
            "ncdu is already the newest version (1.12-1).\n",
            "unzip is already the newest version (6.0-21ubuntu1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JAAwaSXpBzd",
        "outputId": "3af09bce-444b-47da-920a-ec648019305a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: fastai in /usr/local/lib/python3.7/dist-packages (2.5.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai) (3.13)\n",
            "Requirement already satisfied: pillow>6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (7.1.2)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai) (0.11.1+cu111)\n",
            "Requirement already satisfied: fastcore<1.4,>=1.3.22 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.3.27)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai) (2.23.0)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from fastai) (0.0.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai) (1.1.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai) (3.2.2)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.0.0)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.7/dist-packages (from fastai) (2.2.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai) (21.3)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai) (21.1.3)\n",
            "Requirement already satisfied: torch<1.11,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.10.0+cu111)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (3.0.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.6)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (57.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (2.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (0.9.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<4->fastai) (4.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<4->fastai) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<4->fastai) (3.10.0.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->fastai) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai) (2018.9)\n",
            "Requirement already satisfied: skorch in /usr/local/lib/python3.7/dist-packages (0.11.0)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.19.5)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from skorch) (0.8.9)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.7/dist-packages (from skorch) (4.62.3)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->skorch) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->skorch) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install -U scikit-learn fastai \n",
        "!pip3 install -U skorch\n",
        "# scikit-neuralnetwork"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets"
      ],
      "metadata": {
        "id": "qSU-zEHiqFKV"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.torch_core import show_image, show_images"
      ],
      "metadata": {
        "id": "8x2-1qhGtfp7"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "CCQfrh4r8KiC"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris = datasets.load_iris()\n",
        "iris"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8r8udutxqPnV",
        "outputId": "81e62ff1-92fd-4936-be33-2bd4a7008508"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
              " 'data': array([[5.1, 3.5, 1.4, 0.2],\n",
              "        [4.9, 3. , 1.4, 0.2],\n",
              "        [4.7, 3.2, 1.3, 0.2],\n",
              "        [4.6, 3.1, 1.5, 0.2],\n",
              "        [5. , 3.6, 1.4, 0.2],\n",
              "        [5.4, 3.9, 1.7, 0.4],\n",
              "        [4.6, 3.4, 1.4, 0.3],\n",
              "        [5. , 3.4, 1.5, 0.2],\n",
              "        [4.4, 2.9, 1.4, 0.2],\n",
              "        [4.9, 3.1, 1.5, 0.1],\n",
              "        [5.4, 3.7, 1.5, 0.2],\n",
              "        [4.8, 3.4, 1.6, 0.2],\n",
              "        [4.8, 3. , 1.4, 0.1],\n",
              "        [4.3, 3. , 1.1, 0.1],\n",
              "        [5.8, 4. , 1.2, 0.2],\n",
              "        [5.7, 4.4, 1.5, 0.4],\n",
              "        [5.4, 3.9, 1.3, 0.4],\n",
              "        [5.1, 3.5, 1.4, 0.3],\n",
              "        [5.7, 3.8, 1.7, 0.3],\n",
              "        [5.1, 3.8, 1.5, 0.3],\n",
              "        [5.4, 3.4, 1.7, 0.2],\n",
              "        [5.1, 3.7, 1.5, 0.4],\n",
              "        [4.6, 3.6, 1. , 0.2],\n",
              "        [5.1, 3.3, 1.7, 0.5],\n",
              "        [4.8, 3.4, 1.9, 0.2],\n",
              "        [5. , 3. , 1.6, 0.2],\n",
              "        [5. , 3.4, 1.6, 0.4],\n",
              "        [5.2, 3.5, 1.5, 0.2],\n",
              "        [5.2, 3.4, 1.4, 0.2],\n",
              "        [4.7, 3.2, 1.6, 0.2],\n",
              "        [4.8, 3.1, 1.6, 0.2],\n",
              "        [5.4, 3.4, 1.5, 0.4],\n",
              "        [5.2, 4.1, 1.5, 0.1],\n",
              "        [5.5, 4.2, 1.4, 0.2],\n",
              "        [4.9, 3.1, 1.5, 0.2],\n",
              "        [5. , 3.2, 1.2, 0.2],\n",
              "        [5.5, 3.5, 1.3, 0.2],\n",
              "        [4.9, 3.6, 1.4, 0.1],\n",
              "        [4.4, 3. , 1.3, 0.2],\n",
              "        [5.1, 3.4, 1.5, 0.2],\n",
              "        [5. , 3.5, 1.3, 0.3],\n",
              "        [4.5, 2.3, 1.3, 0.3],\n",
              "        [4.4, 3.2, 1.3, 0.2],\n",
              "        [5. , 3.5, 1.6, 0.6],\n",
              "        [5.1, 3.8, 1.9, 0.4],\n",
              "        [4.8, 3. , 1.4, 0.3],\n",
              "        [5.1, 3.8, 1.6, 0.2],\n",
              "        [4.6, 3.2, 1.4, 0.2],\n",
              "        [5.3, 3.7, 1.5, 0.2],\n",
              "        [5. , 3.3, 1.4, 0.2],\n",
              "        [7. , 3.2, 4.7, 1.4],\n",
              "        [6.4, 3.2, 4.5, 1.5],\n",
              "        [6.9, 3.1, 4.9, 1.5],\n",
              "        [5.5, 2.3, 4. , 1.3],\n",
              "        [6.5, 2.8, 4.6, 1.5],\n",
              "        [5.7, 2.8, 4.5, 1.3],\n",
              "        [6.3, 3.3, 4.7, 1.6],\n",
              "        [4.9, 2.4, 3.3, 1. ],\n",
              "        [6.6, 2.9, 4.6, 1.3],\n",
              "        [5.2, 2.7, 3.9, 1.4],\n",
              "        [5. , 2. , 3.5, 1. ],\n",
              "        [5.9, 3. , 4.2, 1.5],\n",
              "        [6. , 2.2, 4. , 1. ],\n",
              "        [6.1, 2.9, 4.7, 1.4],\n",
              "        [5.6, 2.9, 3.6, 1.3],\n",
              "        [6.7, 3.1, 4.4, 1.4],\n",
              "        [5.6, 3. , 4.5, 1.5],\n",
              "        [5.8, 2.7, 4.1, 1. ],\n",
              "        [6.2, 2.2, 4.5, 1.5],\n",
              "        [5.6, 2.5, 3.9, 1.1],\n",
              "        [5.9, 3.2, 4.8, 1.8],\n",
              "        [6.1, 2.8, 4. , 1.3],\n",
              "        [6.3, 2.5, 4.9, 1.5],\n",
              "        [6.1, 2.8, 4.7, 1.2],\n",
              "        [6.4, 2.9, 4.3, 1.3],\n",
              "        [6.6, 3. , 4.4, 1.4],\n",
              "        [6.8, 2.8, 4.8, 1.4],\n",
              "        [6.7, 3. , 5. , 1.7],\n",
              "        [6. , 2.9, 4.5, 1.5],\n",
              "        [5.7, 2.6, 3.5, 1. ],\n",
              "        [5.5, 2.4, 3.8, 1.1],\n",
              "        [5.5, 2.4, 3.7, 1. ],\n",
              "        [5.8, 2.7, 3.9, 1.2],\n",
              "        [6. , 2.7, 5.1, 1.6],\n",
              "        [5.4, 3. , 4.5, 1.5],\n",
              "        [6. , 3.4, 4.5, 1.6],\n",
              "        [6.7, 3.1, 4.7, 1.5],\n",
              "        [6.3, 2.3, 4.4, 1.3],\n",
              "        [5.6, 3. , 4.1, 1.3],\n",
              "        [5.5, 2.5, 4. , 1.3],\n",
              "        [5.5, 2.6, 4.4, 1.2],\n",
              "        [6.1, 3. , 4.6, 1.4],\n",
              "        [5.8, 2.6, 4. , 1.2],\n",
              "        [5. , 2.3, 3.3, 1. ],\n",
              "        [5.6, 2.7, 4.2, 1.3],\n",
              "        [5.7, 3. , 4.2, 1.2],\n",
              "        [5.7, 2.9, 4.2, 1.3],\n",
              "        [6.2, 2.9, 4.3, 1.3],\n",
              "        [5.1, 2.5, 3. , 1.1],\n",
              "        [5.7, 2.8, 4.1, 1.3],\n",
              "        [6.3, 3.3, 6. , 2.5],\n",
              "        [5.8, 2.7, 5.1, 1.9],\n",
              "        [7.1, 3. , 5.9, 2.1],\n",
              "        [6.3, 2.9, 5.6, 1.8],\n",
              "        [6.5, 3. , 5.8, 2.2],\n",
              "        [7.6, 3. , 6.6, 2.1],\n",
              "        [4.9, 2.5, 4.5, 1.7],\n",
              "        [7.3, 2.9, 6.3, 1.8],\n",
              "        [6.7, 2.5, 5.8, 1.8],\n",
              "        [7.2, 3.6, 6.1, 2.5],\n",
              "        [6.5, 3.2, 5.1, 2. ],\n",
              "        [6.4, 2.7, 5.3, 1.9],\n",
              "        [6.8, 3. , 5.5, 2.1],\n",
              "        [5.7, 2.5, 5. , 2. ],\n",
              "        [5.8, 2.8, 5.1, 2.4],\n",
              "        [6.4, 3.2, 5.3, 2.3],\n",
              "        [6.5, 3. , 5.5, 1.8],\n",
              "        [7.7, 3.8, 6.7, 2.2],\n",
              "        [7.7, 2.6, 6.9, 2.3],\n",
              "        [6. , 2.2, 5. , 1.5],\n",
              "        [6.9, 3.2, 5.7, 2.3],\n",
              "        [5.6, 2.8, 4.9, 2. ],\n",
              "        [7.7, 2.8, 6.7, 2. ],\n",
              "        [6.3, 2.7, 4.9, 1.8],\n",
              "        [6.7, 3.3, 5.7, 2.1],\n",
              "        [7.2, 3.2, 6. , 1.8],\n",
              "        [6.2, 2.8, 4.8, 1.8],\n",
              "        [6.1, 3. , 4.9, 1.8],\n",
              "        [6.4, 2.8, 5.6, 2.1],\n",
              "        [7.2, 3. , 5.8, 1.6],\n",
              "        [7.4, 2.8, 6.1, 1.9],\n",
              "        [7.9, 3.8, 6.4, 2. ],\n",
              "        [6.4, 2.8, 5.6, 2.2],\n",
              "        [6.3, 2.8, 5.1, 1.5],\n",
              "        [6.1, 2.6, 5.6, 1.4],\n",
              "        [7.7, 3. , 6.1, 2.3],\n",
              "        [6.3, 3.4, 5.6, 2.4],\n",
              "        [6.4, 3.1, 5.5, 1.8],\n",
              "        [6. , 3. , 4.8, 1.8],\n",
              "        [6.9, 3.1, 5.4, 2.1],\n",
              "        [6.7, 3.1, 5.6, 2.4],\n",
              "        [6.9, 3.1, 5.1, 2.3],\n",
              "        [5.8, 2.7, 5.1, 1.9],\n",
              "        [6.8, 3.2, 5.9, 2.3],\n",
              "        [6.7, 3.3, 5.7, 2.5],\n",
              "        [6.7, 3. , 5.2, 2.3],\n",
              "        [6.3, 2.5, 5. , 1.9],\n",
              "        [6.5, 3. , 5.2, 2. ],\n",
              "        [6.2, 3.4, 5.4, 2.3],\n",
              "        [5.9, 3. , 5.1, 1.8]]),\n",
              " 'data_module': 'sklearn.datasets.data',\n",
              " 'feature_names': ['sepal length (cm)',\n",
              "  'sepal width (cm)',\n",
              "  'petal length (cm)',\n",
              "  'petal width (cm)'],\n",
              " 'filename': 'iris.csv',\n",
              " 'frame': None,\n",
              " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
              " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10')}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(iris.DESCR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRtEs5_Tqzzl",
        "outputId": "5dd5647b-c75d-4ba1-ec82-60ec48d8eb53"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _iris_dataset:\n",
            "\n",
            "Iris plants dataset\n",
            "--------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 150 (50 in each of three classes)\n",
            "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
            "    :Attribute Information:\n",
            "        - sepal length in cm\n",
            "        - sepal width in cm\n",
            "        - petal length in cm\n",
            "        - petal width in cm\n",
            "        - class:\n",
            "                - Iris-Setosa\n",
            "                - Iris-Versicolour\n",
            "                - Iris-Virginica\n",
            "                \n",
            "    :Summary Statistics:\n",
            "\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "                    Min  Max   Mean    SD   Class Correlation\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
            "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
            "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
            "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "    :Class Distribution: 33.3% for each of 3 classes.\n",
            "    :Creator: R.A. Fisher\n",
            "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
            "    :Date: July, 1988\n",
            "\n",
            "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
            "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
            "Machine Learning Repository, which has two wrong data points.\n",
            "\n",
            "This is perhaps the best known database to be found in the\n",
            "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
            "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
            "data set contains 3 classes of 50 instances each, where each class refers to a\n",
            "type of iris plant.  One class is linearly separable from the other 2; the\n",
            "latter are NOT linearly separable from each other.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
            "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
            "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
            "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
            "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
            "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
            "     Structure and Classification Rule for Recognition in Partially Exposed\n",
            "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
            "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
            "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
            "     on Information Theory, May 1972, 431-433.\n",
            "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
            "     conceptual clustering system finds 3 classes in the data.\n",
            "   - Many, many more ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "digits = datasets.load_digits()\n",
        "print(digits.DESCR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0pJsOklrUri",
        "outputId": "12815506-75ab-4e3c-e2e9-b6922c7361f3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _digits_dataset:\n",
            "\n",
            "Optical recognition of handwritten digits dataset\n",
            "--------------------------------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 1797\n",
            "    :Number of Attributes: 64\n",
            "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
            "    :Missing Attribute Values: None\n",
            "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
            "    :Date: July; 1998\n",
            "\n",
            "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
            "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
            "\n",
            "The data set contains images of hand-written digits: 10 classes where\n",
            "each class refers to a digit.\n",
            "\n",
            "Preprocessing programs made available by NIST were used to extract\n",
            "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
            "total of 43 people, 30 contributed to the training set and different 13\n",
            "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
            "4x4 and the number of on pixels are counted in each block. This generates\n",
            "an input matrix of 8x8 where each element is an integer in the range\n",
            "0..16. This reduces dimensionality and gives invariance to small\n",
            "distortions.\n",
            "\n",
            "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
            "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
            "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
            "1994.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
            "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
            "    Graduate Studies in Science and Engineering, Bogazici University.\n",
            "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
            "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
            "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
            "    Electrical and Electronic Engineering Nanyang Technological University.\n",
            "    2005.\n",
            "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
            "    Algorithm. NIPS. 2000.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"digits_x: {digits.data.shape}, digits_y: {digits.target.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GriP0cnErnye",
        "outputId": "130dca01-355b-4e6c-d871-ec5cc545f17d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "digits_x: (1797, 64), digits_y: (1797,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "digits.images[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qf0WCCK-tWN7",
        "outputId": "d033916e-031b-4aaf-c285-22ea53ac9038"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n",
              "       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n",
              "       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n",
              "       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n",
              "       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n",
              "       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n",
              "       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n",
              "       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_image(digits.images[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "qMRVemKjue4I",
        "outputId": "fcde70fa-17cc-40f5-a456-7ad5c50efdc9"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd1949f4410>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABECAYAAAA4E5OyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAB0ElEQVR4nO3cvUtCURzG8aNZtJhFQg0tETgEQiENQVMR1FRLeadGoVVpCIz6E9yC9ihqLSJcAyExopYanHslERoi7N7G6uE+F+9pqOH5jOfHscOXA2dQinieZ+RL9K8P8N8oCFAQoCBAQUAsaDgbXbJ6gp5zk3S2Vtj3Xd+oLdA9qfwdnbXuH9o/2Ddl9zDit64bAhQEKAhQEKAgQEFA4LNriz2txhjjxBu+66XeV7rn+OKUzjJbq3SW3KnQGaMbAhQEKAhQEKAgQEGA9bPbms7QmRO/pLP5Ocd3PXF1Q/csn83Q2cv4B50l6YTTDQEKAhQEKAhQEKAgwPrZfevnW4uPaTpzA55Xpno9EnqPLd0QoCBAQYCCAAUB9q9MH2+5W+FfZabMeei/FUu801mr2RX684LohgAFAQoCFAQoCFAQYP3sdjdcOptI1+msyQ4yOED3ZEdrdHZwMkVnNnRDgIIABQEKAhQEKAiwfnZ7btkDaszm0BGdreTyvuudi09W5xheD/8roSC6IUBBgIIABQEKAhQEWD+7QV9JZrcLdFYs7Pmul+r8V0LVsY72D/ZLuiFAQYCCAAUBCgIUBET0zxB+0g0BCgIUBCgIUBCgIOATX75J5Ol/hWkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_images(digits.images, ncols=5, nrows=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "BR6VwiYMurjg",
        "outputId": "545ebfad-d4ee-4c11-eb3e-047ae6fd1527"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1AAAAKaCAYAAAAwH7hXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3cf7DWdZ338Q+cA8WvWJA4ptxH0SPHOJuFy03iLpIxzJL37gB6t5pYt6SRutss6HbfG3Xf6cxGzpShU8pmpZa4yloLzHb7I8a1s7qgrLu05kHPyWRhVvKcKCLEH8B1uP+wLWmj3nt/35zr4szj8a8zr+udfr24nn5nGnLo0KECAADAbza03gcAAAAcKwQUAABAkIACAAAIElAAAABBAgoAACCo+df9xblD39sw/xd9u5bMTNn56DX3pOz873+an7Iz5eofVN44+EJvwiV5NvTfO6Ren91Iz2yWEx4bk7Jz2si+lJ11n3t35Y1xd2xKuCRPPZ/ZUgbnc/vSwnem7Hzlxs+l7Hz6B/Mqb+w8a2/CJXl8175m26dzfh/0/I9VKTv37B2XsnPn7BmVN/w++IVGemazNLVMTNl5efWIlJ3hc7en7DSSIz2z3kABAAAECSgAAIAgAQUAABAkoAAAAIIEFAAAQJCAAgAACBJQAAAAQQIKAAAgSEABAAAECSgAAIAgAQUAABAkoAAAAIIEFAAAQJCAAgAACBJQAAAAQQIKAAAgSEABAAAENdf7gKiPXnNPys5FY3an7Nz4Wy+m7Pzff36w8sbvXHtlwiWlTLh1U8oOuf517/iUndtbH0nZ+dI5sypvjLuj+h0cHf2zp6XsPHLzF1N2eg6kzJT5x22pvLGqtCVcwuv1rJpReePT7875ffDbN12VsvPUn96SsvP5WSdX3hh9b2/1Q2hY267M+U7a/1R/yk5b2Z6ycyzwBgoAACBIQAEAAAQJKAAAgCABBQAAECSgAAAAggQUAABAkIACAAAIElAAAABBAgoAACBIQAEAAAQJKAAAgCABBQAAECSgAAAAggQUAABAkIACAAAIElAAAABBzQPxIQff/TuVNy4a852ES0p5z7yLUnbGPvlMys4fPTqn8saPp9USLillQsoK/65/9rSUnS9O+ULKTimjUlbe9N3hKTs0pucWvCFlZ8Wu9pSdrzx0bsrO9y/8y8obqxLu4HCnr/pp5Y07r5uRcEkpn+i8O2Xnnr3jUnZG3/t4yg6Np6llYsrO+89/KGVnze3Vf4uWUkpTR873foZaV/dR3fcGCgAAIEhAAQAABAkoAACAIAEFAAAQJKAAAACCBBQAAECQgAIAAAgSUAAAAEECCgAAIEhAAQAABAkoAACAIAEFAAAQJKAAAACCBBQAAECQgAIAAAgSUAAAAEECCgAAIKh5ID7kleOqf8wn+t6WcEkp/U8+k7KT5R+/e2q9T+BX2HHt2ZU31i/+TMIlpUwZNiplJ8uJ3/pR5Y1awh0cHe3XP5eys2bHnJSd+5fm/Ht0btfFlTeGl+0Jl/B6KX8mn3F69Y1SykVjdqfs/NFzOc9+8/HVfzsdfKE34RKybbuyLWXnxrFrU3Y6V45I2Xn6tumVN4buyUmTtmUpM0fkDRQAAECQgAIAAAgSUAAAAEECCgAAIEhAAQAABAkoAACAIAEFAAAQJKAAAACCBBQAAECQgAIAAAgSUAAAAEECCgAAIEhAAQAABAkoAACAIAEFAAAQJKAAAACCBBQAAEBQ80B8yCvjqnfaXZtmJlxSypSyOWUnS/PY/ZU3Du4ZnnAJr9d67cbKG0tXLUy4pJT7tnwrZSfLgQkjK2/4LzdHR1PLxMob3X9+SsIlpVw256GUnSwjLnm58kYt4Q7y9T/5TMrOfzvz91N2pj2wM2WnPFB9Ysu8E6qPlFIOvtCbsjMY7L60+u/Rp5fcknBJKR2blqTsTCpdKTvb5n258sbbP3NVwiVHn98xAAAAQQIKAAAgSEABAAAECSgAAIAgAQUAABAkoAAAAIIEFAAAQJCAAgAACBJQAAAAQQIKAAAgSEABAAAECSgAAIAgAQUAABAkoAAAAIIEFAAAQJCAAgAACBJQAAAAQc0D8SFv3N1feeO/vu37CZeUsidlpZTm41tSdi6c+k+VN/76/t9LuARi+s4cUXnj+M6EQ/gPnv50a+WNbfP+MuGSPDOW/1nKzrjeTSk7DF4HX+hN2dky74SUnR/dNqbyRu8nxydcUsqUK3P+3gwGb9hT/Tdtz4F9CZeU0jXzrpSdFU+2p+xkOPGvnk3ZqaWsHJk3UAAAAEECCgAAIEhAAQAABAkoAACAIAEFAAAQJKAAAACCBBQAAECQgAIAAAgSUAAAAEECCgAAIEhAAQAABAkoAACAIAEFAAAQJKAAAACCBBQAAECQgAIAAAhqHogPeVP3nsobn5z0zYRLSvnAkqtTdoYt+GHKTobJH9tU7xOABtD21VrljRXT2xMuKWX5hO6Unc0rVqXsnLtofuWNfXedkHBJKePu8J2dqWfVjJSdE/5uSMrOK+Ny/tv016Z+rvLGgp9cmXAJrzdy7eOVNz6y9ncTLimlf/a0lJ2bv/aFlJ2OTUsqb0zq7Uq45OjzBgoAACBIQAEAAAQJKAAAgCABBQAAECSgAAAAggQUAABAkIACAAAIElAAAABBAgoAACBIQAEAAAQJKAAAgCABBQAAECSgAAAAggQUAABAkIACAAAIElAAAABBAgoAACCoeSA+pP/JZypvXLjqmoRLSvnENXen7Nz4/TkpO//4jqaUHRpPrbcvZefcrvkpOw93rE/ZOfh7e6qPrKw+wX80tHNL5Y3OM0YkXFLKw7MXp+wc/MSPU3Yynv/J51yecEkp4+5ImeFnhv0k58/Rj/zFPSk7WRZsvLLyxikXfyfhEhrVsF0vpexMGTYqZWf86tEpO8cCb6AAAACCBBQAAECQgAIAAAgSUAAAAEECCgAAIEhAAQAABAkoAACAIAEFAAAQJKAAAACCBBQAAECQgAIAAAgSUAAAAEECCgAAIEhAAQAABAkoAACAIAEFAAAQJKAAAACChhw6dKjeNwAAABwTvIECAAAIElAAAABBAgoAACBIQAEAAAQJKAAAgCABBQAAECSgAAAAggQUAABAkIACAAAIElAAAABBAgoAACBIQAEAAAQJKAAAgCABBQAAECSgAAAAggQUAABAkIACAAAIElAAAABBAgoAACBIQAEAAAQJKAAAgCABBQAAECSgAAAAggQUAABAkIACAAAIElAAAABBAgoAACBIQAEAAAQ1/7q/OHfoew8N1CG/yQmPjUnZ2fx8a8rOpAu6UnYGow399w6p12c30jObJevZP21kX8pO5xkjUnYaST2f2VIa67ndce3ZKTv7x/an7Fw25+GUneUTuitv9BzYl3BJKUtnLEzZeeAHN/uuLaX03DY9ZWflrHtSdq755iUpO+3XP1d5o9ab872fxe+D1+zfcFLKzsljfpyys/OsvSk7g9GRnllvoAAAAIIEFAAAQJCAAgAACBJQAAAAQQIKAAAgSEABAAAECSgAAIAgAQUAABAkoAAAAIIEFAAAQJCAAgAACBJQAAAAQQIKAAAgSEABAAAECSgAAIAgAQUAABDUXO8DouYftyVl5/bWR1J2ys6cmXX7RlfeWHVaW8IlZNt96cyUnQdbV6XsnLrmipSdtvJYyg6D2/A9Of997v5PvitlZ8NVp1feOHnMjxMuKaXW25eyw2veNbW73icc5oY/WJ2ys37mtMobO89KOITDNHW0V954uGNNwiWJkn7TrthV/e9N5xkjEi45+ryBAgAACBJQAAAAQQIKAAAgSEABAAAECSgAAIAgAQUAABAkoAAAAIIEFAAAQJCAAgAACBJQAAAAQQIKAAAgSEABAAAECSgAAIAgAQUAABAkoAAAAIIEFAAAQFBzvQ+I2vryiSk7C0Z1p+z0HNiXsvPxJxdV3jip5YcJl5RS6+1L2eE1C67+u3qfcJhT1r1a7xM4BrReu7HeJxzm2ZVnpexc1vJM5Y1H556UcEkppexN2qGUUr69tT1lZ/PY1pSdSRd0pex8fvsDlTcuW3h1wiWljFz7eMrOYHBgwsh6n/Bzi3fMStnZ/HzOs/+pM9ZX3ugsbQmXHH3eQAEAAAQJKAAAgCABBQAAECSgAAAAggQUAABAkIACAAAIElAAAABBAgoAACBIQAEAAAQJKAAAgCABBQAAECSgAAAAggQUAABAkIACAAAIElAAAABBAgoAACBIQAEAAAQ11/uAqA29p6fsLJ/QnbIzZdiolJ3+746tvFHr7Uq4hGxTRzyfsrNiV3vKztDOLSk7NK6XFr6z8sbOc4YkXJLn/vNvqPcJP7fm4jkpO8ev7EvZ4TVtX62l7Gy4+66UncWPzUrZ2bq/pfLGmJ6fJFxSSs7f4cFh2DM5f7Zn6J0/ImVnxvodKTtTh/cmrLQlbBx93kABAAAECSgAAIAgAQUAABAkoAAAAIIEFAAAQJCAAgAACBJQAAAAQQIKAAAgSEABAAAECSgAAIAgAQUAABAkoAAAAIIEFAAAQJCAAgAACBJQAAAAQQIKAAAgSEABAAAENdf7gKjhc7en7Mxa+OGUnV1vb0rZeXrJLZU33lquSriklNZrN6bs8Jqpw3tTdtb/aFrKzo5r35ayM/neH1XeqHV1J1zCLxvT85PKG61XvZJwSSlfnPJXKTtZLlt6deWN49f6jmxEr4wfXu8TDnN76yMpO+fNvbDyhu/afLXevsobK3a1J1xSyn1bvpWyM/mBy1N2PvaWBypvNHXk/L052s++N1AAAABBAgoAACBIQAEAAAQJKAAAgCABBQAAECSgAAAAggQUAABAkIACAAAIElAAAABBAgoAACBIQAEAAAQJKAAAgCABBQAAECSgAAAAggQUAABAkIACAAAIElAAAABBzfU+YKCNXPt4ys6E8s6UnQyvtO6v9wn8Cl/fc2bKzu2tj6TsrDi/L2Vn+ZLuyhtz37c44ZJShnZuSdkZLGpd1f/ZDJ+bcEgpZcrOUSk7M5ZfmbIzbu2mlB1y9c+eVnnjkZu/mHBJKaeuuSJl542te1N2Ft39ROWNR9/3joRLcr5b+IXOM0ak7Dw8O+fP0imd1Z+1Ukr5/dv+tPLGyTf+MOGSvD/LjsQbKAAAgCABBQAAECSgAAAAggQUAABAkIACAAAIElAAAABBAgoAACBIQAEAAAQJKAAAgCABBQAAECSgAAAAggQUAABAkIACAAAIElAAAABBAgoAACBIQAEAAAQ11/uAqN2XzkzZecOe/pSdtv+1NWUnw6S/bar3CfwKd/7NnJSd5Uu6U3Y29J6esvPfx/5z5Y3nFrwh4ZJS2jpTZnidntum5+wc+IeUnQn3fz9lp5ayQrZhzzxfeaPnwL6ES0ppv/65lJ0Dp5+YsrP87urf/adefm7CJaW0LUuZIdnQzi0pO1nf+w/OuanyxmVLr064pJThZXvKzpF4AwUAABAkoAAAAIIEFAAAQJCAAgAACBJQAAAAQQIKAAAgSEABAAAECSgAAIAgAQUAABAkoAAAAIIEFAAAQJCAAgAACBJQAAAAQQIKAAAgSEABAAAECSgAAIAgAQUAABDUXO8Don54zoGUnW3zvpyyk6Vj06LKG5PWPp5wCdkmr3o2Z6f18pSdB+fclLLz4Z6LK2+csu7VhEs4Gj40/ZGUnUs++WcpO+N6N6Xs0JhqvX2VNzK+k0op5eEt61N2eg7sS9k5t6v6/672659LuKSUWsoK/67ntukpO++a2p2yM3tkzvf+H3/gTypvjOw8Nn7TegMFAAAQJKAAAACCBBQAAECQgAIAAAgSUAAAAEECCgAAIEhAAQAABAkoAACAIAEFAAAQJKAAAACCBBQAAECQgAIAAAgSUAAAAEECCgAAIEhAAQAABAkoAACAIAEFAAAQNOTQoUP1vgEAAOCY4A0UAABAkIACAAAIElAAAABBAgoAACBIQAEAAAQJKAAAgCABBQAAECSgAAAAggQUAABAkIACAAAIElAAAABBAgoAACBIQAEAAAQJKAAAgCABBQAAECSgAAAAggQUAABAkIACAAAIElAAAABBAgoAACBIQAEAAAQJKAAAgCABBQAAECSgAAAAggQUAABAkIACAAAIElAAAABBAgoAACCo+df9xblD33tooA75TZpaJqbsPP3p1pSdB+fclLLz4Z6LK28Mn7s94ZI8G/rvHVKvz26kZ7bRXPm9Z1N2tr58YuWNR+eelHBJKbXevpSdej6zpTTWc7v70pkpOx1XPJWy0zt/RMpO1rPSSAbDd21TR3vljaevGZNwSd6f61v3t6TsLHvkosobbV+tJVxSytDOLSk7g+GZbSTPrjwrZef+829I2Vk6Y2HljUb7rj7SM+sNFAAAQJCAAgAACBJQAAAAQQIKAAAgSEABAAAECSgAAIAgAQUAABAkoAAAAIIEFAAAQJCAAgAACBJQAAAAQQIKAAAgSEABAAAECSgAAIAgAQUAABAkoAAAAIIEFAAAQFBzvQ+Ienn1iJSdbR1fTtk5dc01KTs3/MHqyhufXPaBhEtKOX7lxpQdcu2+dGbKzoJR30na6a68cd6EdyRcUkrp7cvZ4edWX/fZlJ2t+1tSdj52Zc73W+u1npVGtHfKb1Xe+ND0b1c/pJTynr/J+XO9f+zBlJ1t86r/Xjl1zxUJl5TS1pkyw880tUxM2cn4DVlKKV/fc2bKToasvze1o/z7wBsoAACAIAEFAAAQJKAAAACCBBQAAECQgAIAAAgSUAAAAEECCgAAIEhAAQAABAkoAACAIAEFAAAQJKAAAACCBBQAAECQgAIAAAgSUAAAAEECCgAAIEhAAQAABDUPxIc0dbRX3ni4Y03CJaV0bFqUstO27LGUnWVjL6o+8rb91TdKKcenrJBt+cfvrPcJh1m8Y1bljVpXd8IlHA1f33Nmys6jc09K2Tlr/XdTdnZemzJDspFrH6+80bl2RMIlpYxelvPflK+76p6UnZ4D+ypvnLLu1YRLyLb9ljen7Ewd3puyc/Pl783Z2fyFyhsf7rk44ZJShs9NmTkib6AAAACCBBQAAECQgAIAAAgSUAAAAEECCgAAIEhAAQAABAkoAACAIAEFAAAQJKAAAACCBBQAAECQgAIAAAgSUAAAAEECCgAAIEhAAQAABAkoAACAIAEFAAAQJKAAAACCmgfkU3btHpCPiRi/enS9TzjM0D0D84+A/5ymlomVN7bf8uaES0pZMOo7KTsMfk0d7ZU37vpeznfSpN6ulJ35xz2bsrOqtKXsMHiNP+/5ep9wmKXnfbDyxtCuLQmX8Ho7rj278sbTM29JuKSUt9760ZSdyc/kfM9OGTaq8saOp96ScEkpbWV7ys6ReAMFAAAQJKAAAACCBBQAAECQgAIAAAgSUAAAAEECCgAAIEhAAQAABAkoAACAIAEFAAAQJKAAAACCBBQAAECQgAIAAAgSUAAAAEECCgAAIEhAAQAABAkoAACAIAEFAAAQ1DwQH7L37MkD8TGQ5sDpJ1bemHHiswmXlLJu3+iUnQWjXkzZ+fbW9sobU8oTCZfwy2pd3ZU3Tvo/1f/5llJKLWUl77m9tWVi5Y1ab1/CJTSqEUvfmLIz9b7elJ2Xb3yl8sbwuQmHcJhXWvfX+4Sfe//5D6XsTF30fMpOhuP+ZUi9TwjxBgoAACBIQAEAAAQJKAAAgCABBQAAECSgAAAAggQUAABAkIACAAAIElAAAABBAgoAACBIQAEAAAQJKAAAgCABBQAAECSgAAAAggQUAABAkIACAAAIElAAAABBAgoAACCoeSA+ZMzGbQPxMSGvjs1pxjEtE1N2Wn/7B5U3mv9ifMIlvN7Qzi2VN3aelXBIKWXFpe9P2VmwYlXKzoNzbqq88ZHyuwmXcDTUurpTdl5YdnbKTs+Bf0jZqfX2pewweGU9+0vP+2DKzhfvu63yxmULr064pJSRax9P2RkM3vqxHZU3OsYuSriklLXTb03ZmTJsVMrOun2jK2+Mu2NTwiVHnzdQAAAAQQIKAAAgSEABAAAECSgAAIAgAQUAABAkoAAAAIIEFAAAQJCAAgAACBJQAAAAQQIKAAAgSEABAAAECSgAAIAgAQUAABAkoAAAAIIEFAAAQJCAAgAACGoeiA+p9fZV3li8Y1bCJaV0XPFUys7mP2xN2Sk/rT4xqXNL9REa1hv29Nf7hMNs3d9S7xM4inpum56ys23eLSk7PQdSZlL+dw3dk/NHZvuXd6fsDAZNLRMrb+x6z6kJl5Ty6rghKTsXLn4oZWfKsFGVN356clPCJaWMTFkZHDJ+0066oPpGKaUsbVmYsnPflm+l7Hz8yfmVNyaVroRLjj5voAAAAIIEFAAAQJCAAgAACBJQAAAAQQIKAAAgSEABAAAECSgAAIAgAQUAABAkoAAAAIIEFAAAQJCAAgAACBJQAAAAQQIKAAAgSEABAAAECSgAAIAgAQUAABAkoAAAAIKa631AVO/8ESk72295c8rOotOeSNl5+CNnp+wweI3ZuC1lZ8Wu9pSd5RO6K2/c2jIx4ZJSar19KTv8QttXayk75/6X+Sk7O556S8rOh+Y8XHnjey/lPLfP/v3UlJ1BYcK4yhMdVzyVcEjjOber+r9Dx6/cmHAJjSrrN23PgX0pO+NXj07ZORZ4AwUAABAkoAAAAIIEFAAAQJCAAgAACBJQAAAAQQIKAAAgSEABAAAECSgAAIAgAQUAABAkoAAAAIIEFAAAQJCAAgAACBJQAAAAQQIKAAAgSEABAAAECSgAAIAgAQUAABA05NChQ/W+AQAA4JjgDRQAAECQgAIAAAgSUAAAAEECCgAAIEhAAQAABAkoAACAIAEFAAAQJKAAAACCBBQAAECQgAIAAAgSUAAAAEECCgAAIEhAAQAABAkoAACAIAEFAAAQJKAAAACCBBQAAECQgAIAAAgSUAAAAEECCgAAIEhAAQAABAkoAACAIAEFAAAQJKAAAACCBBQAAECQgAIAAAgSUAAAAEHNv+4vzh363kMZH7L70pmVNzqueCrhklJOG9mXsrN8QnfKTobz5l6YslPryvnftKH/3iEpQ/8fsp7ZRvLsyrNSdu4//4aUnaUzFlbeqPXm/HuYpZ7PbCmN9dw2tUxM2en+81NSdrKe24VPLKm8MemCroRL8viufc2/faMjZaf/u2NTdt5//kMpO196YlbljSkffCLhkjye2de8sOzslJ3rrvpays4N/3NRys7ItY+n7DSSIz2z3kABAAAECSgAAIAgAQUAABAkoAAAAIIEFAAAQJCAAgAACBJQAAAAQQIKAAAgSEABAAAECSgAAIAgAQUAABAkoAAAAIIEFAAAQJCAAgAACBJQAAAAQQIKAAAgSEABAAAENQ/Eh4xatLPyxu2tjyRcUkrPgX0pO6euuSZl54S/P1R5Y2TX4wmX0KjOmdmVsrN1f0vKTq23L2WHfP2zp1XemP35jQmXlHLj2LUpO1nP7afOWF95Y1VpS7iEbC/tGZGyM/Jte1J2vvfSxJSdB+fcVHljaccHEy4ppdbVnbLDa8af93zKzoJRL6bsfPySnJ2ROV/7xwRvoAAAAIIEFAAAQJCAAgAACBJQAAAAQQIKAAAgSEABAAAECSgAAIAgAQUAABAkoAAAAIIEFAAAQJCAAgAACBJQAAAAQQIKAAAgSEABAAAECSgAAIAgAQUAABDUPBAfsuOpt1TeWHfy6IRLSrnpX+en7LRf/1zKTq23L2WHxtM/e1rKzu2tt6fsvPXWq1J2WsvGlB3y7Zn8xsobd31vesIlpXReMCJl59++0ZGyM+PEHQkrexM2yDbpb5tSdpqvejFlZ/PzrSk7H957ceWN4V3dCZeQLeN3cSl5v427Zt6VsnNex4WVN2rHyDPrDRQAAECQgAIAAAgSUAAAAEECCgAAIEhAAQAABAkoAACAIAEFAAAQJKAAAACCBBQAAECQgAIAAAgSUAAAAEECCgAAIEhAAQAABAkoAACAIAEFAAAQJKAAAACCBBQAAEBQc70PiFow6sWcnY71KTvrHh2dsrPqtLaUHRpP35kj6n3CYSbf+6OUnVrKCkfDuDs2Vd4Yu21awiWl7L50ZsrO2umfTdlZ+MSSyhsndRxMuKSUWld3yg6vGbNxW8rOfTd/K2WnY9OilJ0Rl7xcecP3dWNqv/65lJ31M3O+r9fn/DwoL9/4SuWN4XMTDhkA3kABAAAECSgAAIAgAQUAABAkoAAAAIIEFAAAQJCAAgAACBJQAAAAQQIKAAAgSEABAAAECSgAAIAgAQUAABAkoAAAAIIEFAAAQJCAAgAACBJQAAAAQQIKAAAgSEABAAAENQ/Eh7Rf/1zljbfvuCrhkjz/8tFbUnZWpazQiPaPrfcFh7tvw5qUnRW72itvrPvcuxMuKWXcHZtSdviFDXffXu8TfsmolJWumXdV3lj8lVkJl5Sy86yUGX6mZf3LKTsZ322llDJ+9eiUnVpvV8oOjafW25ey03DfJRvGV57onz0t4ZBShnZuSdk54v5RXQcAABhEBBQAAECQgAIAAAgSUAAAAEECCgAAIEhAAQAABAkoAACAIAEFAAAQJKAAAACCBBQAAECQgAIAAAgSUAAAAEECCgAAIEhAAQAABAkoAACAIAEFAAAQJKAAAACCmgfiQ2q9fZU3jl9ZfaOUUnZfOjNlJ0v/7GmVN4Z2bkm4hGzrF38maWlUysrkBy5P2cmw8uN3puysuqMtZWewaGqZWHnj1DVXJFxSyjkzu1J25h+X8/12zTcvqbxxyrpXEy4pZWjxnd2IHp17UspO2/qtKTs716bMwIDZd9cJlTdGfWJnwiWlDO9MmTkib6AAAACCBBQAAECQgAIAAAgSUAAAAEECCgAAIEhAAQAABAkoAACAIAEFAAAQJKAAAACCBBQAAECQgAIAAAgSUAAAAEECCgAAIEhAAQAABAkoAACAIAEFAAAQ1DwQH9LUMrHyxq73nJpwSSmrr/tsys6KXWem7Azt3JKyQ+P54w/8Sc7Ol+9N2cny1hv2Vt5YMO/FhEtKubWjPWVnsKj19lXeaFtWfaOUUjZ/oyNl57SROfe0LXssZYdcGb8PNj//5vPclIEAAAG7SURBVIRLSjlpwsGUnfnHbUzZWVXaUnZoPBnPfSml7D17cspOlr0nD6m8sbljfcIlpZzXcWHKzpF4AwUAABAkoAAAAIIEFAAAQJCAAgAACBJQAAAAQQIKAAAgSEABAAAECSgAAIAgAQUAABAkoAAAAIIEFAAAQJCAAgAACBJQAAAAQQIKAAAgSEABAAAECSgAAIAgAQUAABDUPBAfsvfsyZU3Vl/32YRLSpkybFTKzqPve0fKTindSTs0mqGdW1J2PnbXB1J2Hlz8mZSdKfOq/zt0btf8hEtKGd7l359GNfFNL6bsfOmJWSk7U8oTKTvkqvX2Vd6Y+KYRCZeUsmTdQyk7Kz71/pSdcWVTyg6NZ9uVbSk7Ty+5JWUny4pd7ZU3sn4fjNi1O2XnSLyBAgAACBJQAAAAQQIKAAAgSEABAAAECSgAAIAgAQUAABAkoAAAAIIEFAAAQJCAAgAACBJQAAAAQQIKAAAgSEABAAAECSgAAIAgAQUAABAkoAAAAIIEFAAAQJCAAgAACBpy6NChet8AAABwTPAGCgAAIEhAAQAABAkoAACAIAEFAAAQJKAAAACCBBQAAEDQ/wOM8MK422rITgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x864 with 20 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVC"
      ],
      "metadata": {
        "id": "cs5jC0FC1YM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn import metrics\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "#: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "#: https://scikit-learn.org/0.16/modules/generated/sklearn.cross_validation.train_test_split.html\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "#: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n",
        "\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "1JYv0UpD1Za2"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##\n",
        "# clf = SVC()\n",
        "##\n",
        "clf = KMeans(n_clusters=10, max_iter=10_000)\n",
        "##"
      ],
      "metadata": {
        "id": "fnAK6jIu1iwC"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##\n",
        "# train_x = digits.data[0:1000]\n",
        "# train_y = digits.target[0:1000]\n",
        "# val_x = digits.data[1000:]\n",
        "# val_y = digits.target[1000:]\n",
        "##\n",
        "train_x, val_x, train_y, val_y = \\\n",
        "train_test_split(digits.data, digits.target, test_size=0.25)\n",
        "\n",
        "# normalize the data via scaling\n",
        "t = MinMaxScaler()\n",
        "t.fit(train_x)\n",
        "train_x = t.transform(train_x)\n",
        "val_x = t.transform(val_x)\n",
        "##\n",
        "train_x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RunldO35Ajl",
        "outputId": "3251927a-d913-42c1-858c-879747789bec"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1347, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(train_x, train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x42KB22o1xrC",
        "outputId": "f1170895-91f7-4b4e-ebe9-9668b727de61"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(max_iter=10000, n_clusters=10)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = clf.predict(val_x)\n",
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIQuLrZ75Q1V",
        "outputId": "8ec3ed24-c7f8-4b1d-d001-c051fc4b0242"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 4, 9, 2, 6, 3, 5, 9, 8, 3, 5, 5, 1, 7, 0, 3, 9, 3, 3, 2, 9,\n",
              "       1, 4, 3, 5, 4, 4, 1, 3, 1, 2, 2, 9, 2, 9, 6, 3, 9, 6, 1, 3, 6, 9,\n",
              "       8, 8, 5, 5, 8, 6, 2, 9, 3, 8, 7, 4, 5, 7, 3, 7, 2, 1, 2, 1, 2, 2,\n",
              "       3, 0, 9, 1, 7, 0, 6, 1, 5, 6, 9, 0, 3, 5, 5, 0, 7, 5, 3, 2, 1, 6,\n",
              "       0, 9, 7, 4, 2, 8, 6, 9, 6, 2, 9, 1, 8, 9, 8, 1, 1, 5, 2, 7, 6, 8,\n",
              "       5, 1, 2, 5, 3, 6, 5, 8, 2, 4, 5, 8, 1, 7, 1, 1, 7, 1, 4, 0, 6, 6,\n",
              "       2, 5, 3, 8, 5, 6, 5, 9, 1, 2, 7, 4, 9, 5, 2, 1, 3, 6, 9, 2, 9, 7,\n",
              "       6, 8, 2, 0, 6, 2, 3, 0, 7, 7, 1, 2, 8, 6, 7, 5, 8, 7, 9, 7, 9, 2,\n",
              "       4, 2, 8, 0, 7, 6, 6, 8, 4, 2, 0, 8, 5, 3, 3, 2, 3, 6, 0, 0, 0, 7,\n",
              "       5, 1, 9, 1, 3, 4, 8, 3, 2, 7, 3, 0, 8, 3, 6, 3, 7, 6, 3, 0, 3, 7,\n",
              "       2, 4, 7, 7, 9, 2, 3, 4, 7, 7, 3, 9, 1, 3, 0, 4, 6, 3, 4, 0, 4, 4,\n",
              "       2, 3, 5, 2, 1, 3, 0, 7, 3, 7, 7, 8, 3, 4, 7, 4, 3, 4, 9, 5, 1, 9,\n",
              "       7, 4, 3, 1, 8, 5, 9, 4, 9, 1, 7, 9, 6, 2, 7, 4, 8, 9, 3, 3, 5, 2,\n",
              "       5, 7, 8, 6, 3, 1, 6, 2, 5, 1, 3, 7, 1, 9, 5, 7, 8, 5, 3, 1, 5, 7,\n",
              "       4, 7, 4, 2, 2, 1, 8, 4, 3, 8, 2, 8, 7, 9, 5, 6, 8, 2, 1, 5, 2, 3,\n",
              "       2, 9, 2, 2, 3, 3, 3, 9, 7, 6, 6, 9, 2, 2, 4, 1, 7, 8, 8, 9, 3, 4,\n",
              "       5, 2, 7, 1, 4, 6, 4, 6, 1, 3, 5, 6, 6, 4, 7, 3, 6, 8, 6, 9, 9, 9,\n",
              "       5, 8, 9, 8, 3, 2, 6, 0, 9, 8, 5, 2, 3, 3, 1, 7, 2, 1, 7, 3, 7, 4,\n",
              "       1, 2, 8, 5, 1, 8, 5, 8, 6, 0, 7, 8, 7, 3, 3, 3, 6, 1, 2, 5, 1, 2,\n",
              "       2, 7, 3, 7, 5, 9, 3, 6, 5, 6, 8, 5, 3, 7, 5, 0, 3, 5, 8, 4, 5, 4,\n",
              "       9, 4, 6, 7, 0, 3, 6, 8, 5, 1], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99BSEKqIiS5m",
        "outputId": "989c5439-fd75-4c2b-d068-98a0bbf5e3c3"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([8, 8, 5, 3, 1, 0, 9, 6, 2, 7, 3, 6, 6, 2, 4, 9, 9, 3, 9, 9, 1, 3,\n",
              "       2, 8, 9, 6, 5, 5, 2, 9, 2, 1, 4, 3, 8, 3, 0, 9, 3, 0, 2, 9, 0, 3,\n",
              "       7, 7, 6, 6, 7, 0, 1, 3, 9, 9, 4, 5, 6, 4, 8, 4, 1, 2, 1, 2, 8, 1,\n",
              "       5, 9, 3, 2, 4, 6, 0, 2, 6, 0, 3, 1, 9, 6, 6, 8, 4, 6, 9, 1, 1, 0,\n",
              "       1, 3, 4, 9, 1, 7, 0, 3, 0, 1, 3, 2, 7, 3, 7, 2, 2, 5, 8, 4, 0, 7,\n",
              "       6, 1, 8, 6, 9, 0, 6, 7, 3, 5, 6, 7, 2, 4, 2, 2, 4, 2, 9, 9, 0, 0,\n",
              "       1, 6, 8, 7, 6, 0, 6, 3, 2, 8, 4, 5, 3, 6, 8, 2, 9, 0, 3, 1, 8, 4,\n",
              "       0, 2, 3, 1, 0, 3, 9, 1, 4, 4, 2, 1, 7, 0, 4, 6, 7, 4, 3, 4, 3, 1,\n",
              "       9, 1, 7, 9, 4, 0, 0, 7, 5, 1, 9, 7, 6, 9, 3, 1, 9, 0, 1, 1, 8, 4,\n",
              "       6, 2, 3, 2, 9, 5, 7, 9, 8, 4, 9, 9, 7, 5, 0, 9, 4, 0, 8, 4, 9, 4,\n",
              "       8, 5, 4, 4, 3, 8, 8, 5, 4, 4, 3, 3, 2, 9, 9, 5, 0, 5, 5, 9, 5, 5,\n",
              "       8, 9, 6, 1, 2, 9, 1, 4, 5, 4, 4, 7, 2, 5, 4, 5, 3, 5, 8, 6, 2, 2,\n",
              "       4, 5, 9, 2, 7, 6, 2, 5, 3, 2, 4, 2, 0, 8, 4, 5, 7, 3, 9, 8, 6, 1,\n",
              "       6, 4, 7, 0, 9, 2, 0, 1, 6, 2, 8, 4, 2, 3, 6, 4, 7, 6, 9, 2, 8, 4,\n",
              "       5, 4, 5, 1, 1, 1, 7, 5, 9, 9, 8, 7, 4, 3, 6, 0, 7, 7, 2, 6, 4, 9,\n",
              "       8, 3, 8, 8, 9, 3, 9, 3, 4, 0, 0, 3, 1, 8, 5, 2, 4, 2, 7, 2, 8, 5,\n",
              "       6, 8, 4, 2, 5, 0, 8, 0, 2, 9, 6, 0, 0, 5, 4, 9, 0, 8, 0, 3, 3, 3,\n",
              "       6, 7, 9, 7, 5, 8, 0, 1, 3, 8, 6, 2, 5, 9, 2, 4, 8, 2, 4, 9, 4, 5,\n",
              "       2, 8, 4, 6, 2, 7, 6, 7, 0, 1, 4, 7, 4, 9, 9, 8, 0, 8, 8, 6, 2, 8,\n",
              "       1, 4, 9, 4, 6, 9, 9, 0, 6, 0, 7, 6, 9, 4, 6, 1, 8, 6, 7, 5, 6, 5,\n",
              "       3, 9, 0, 4, 1, 9, 0, 7, 6, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "permu = {\n",
        "    6: 1,\n",
        "    9: 4,\n",
        "    1: 0,\n",
        "    5: 5,\n",
        "    7: 3,\n",
        "    2: 6,\n",
        "    3: 9,\n",
        "    4: 7,\n",
        "    8: 8,\n",
        "    0: 2,\n",
        "}\n",
        "preds_permuted = [permu[p] for p in preds]\n",
        "sum(preds_permuted == val_y)/len(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JitkdSeQiaMn",
        "outputId": "1f623596-7f25-4b3c-c66f-e8deb560e0a9"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.completeness_score(val_y, preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDpqTWGTkgo7",
        "outputId": "804c1f8f-e242-454d-daae-9182504664a5"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7516256174062698"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.homogeneity_score(val_y, preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzSWQHqqn7qs",
        "outputId": "5b3e045e-429a-4d4f-d874-4016d9d4013d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7465856528198382"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(preds == val_y)/len(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1kCyksI5b5j",
        "outputId": "6a254661-8da8-4a1b-8a26-4a66d4d0307f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.03111111111111111"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# reddit_sample"
      ],
      "metadata": {
        "id": "ljKdywrTTrn3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## loading the data"
      ],
      "metadata": {
        "id": "ResTfCkD9MKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!aria2c 'https://archive.ics.uci.edu/ml/machine-learning-databases/00441/repeat_consumption_data.zip'\n",
        "!unzip repeat_consumption_data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1tsr3FY-Coy",
        "outputId": "0375e917-dc7b-4a1f-ba32-5d48da36c244"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "01/11 21:09:30 [\u001b[1;32mNOTICE\u001b[0m] Downloading 1 item(s)\n",
            "\n",
            "01/11 21:09:31 [\u001b[1;32mNOTICE\u001b[0m] File already exists. Renamed to /content/repeat_consumption_data.1.zip.\n",
            "\u001b[0m\n",
            "01/11 21:09:35 [\u001b[1;32mNOTICE\u001b[0m] Download complete: /content/repeat_consumption_data.1.zip\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "6d136c|\u001b[1;32mOK\u001b[0m  |    14MiB/s|/content/repeat_consumption_data.1.zip\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "Archive:  repeat_consumption_data.zip\n",
            "replace data/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace __MACOSX/data/._.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"/content/data/reddit_sample/train.csv\""
      ],
      "metadata": {
        "id": "E0Gf8hj32LvP"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_raw = pd.read_csv(train_path, names=['x','y','z'])\n",
        "train_raw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "-sVo_2Hz55Fd",
        "outputId": "19169b97-5626-43b4-fdfd-43f1c30faad6"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-207f5a2a-4af3-42ce-8e5c-56a212e61835\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>741</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>877</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>5773</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>6492</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>7083</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379545</th>\n",
              "      <td>20023</td>\n",
              "      <td>17045</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379546</th>\n",
              "      <td>20023</td>\n",
              "      <td>18347</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379547</th>\n",
              "      <td>20023</td>\n",
              "      <td>21204</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379548</th>\n",
              "      <td>20023</td>\n",
              "      <td>21342</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379549</th>\n",
              "      <td>20023</td>\n",
              "      <td>21385</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>379550 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-207f5a2a-4af3-42ce-8e5c-56a212e61835')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-207f5a2a-4af3-42ce-8e5c-56a212e61835 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-207f5a2a-4af3-42ce-8e5c-56a212e61835');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            x      y    z\n",
              "0           0    741    1\n",
              "1           0    877  189\n",
              "2           0   5773    1\n",
              "3           0   6492    3\n",
              "4           0   7083    2\n",
              "...       ...    ...  ...\n",
              "379545  20023  17045    1\n",
              "379546  20023  18347    2\n",
              "379547  20023  21204    2\n",
              "379548  20023  21342    1\n",
              "379549  20023  21385    0\n",
              "\n",
              "[379550 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_mat = train_raw.pivot(index=\"x\", columns=\"y\", values=\"z\")\n",
        "train_mat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "UCboZRQn6ooL",
        "outputId": "0fad15d8-82d5-4f48-fb3e-f097dba1bb3f"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d7aeb078-0cb3-43f4-85dd-9fcb17f44f41\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>y</th>\n",
              "      <th>1</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>20</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>25</th>\n",
              "      <th>29</th>\n",
              "      <th>31</th>\n",
              "      <th>33</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>39</th>\n",
              "      <th>41</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>56</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>...</th>\n",
              "      <th>21331</th>\n",
              "      <th>21333</th>\n",
              "      <th>21334</th>\n",
              "      <th>21335</th>\n",
              "      <th>21338</th>\n",
              "      <th>21340</th>\n",
              "      <th>21341</th>\n",
              "      <th>21342</th>\n",
              "      <th>21344</th>\n",
              "      <th>21345</th>\n",
              "      <th>21346</th>\n",
              "      <th>21347</th>\n",
              "      <th>21349</th>\n",
              "      <th>21351</th>\n",
              "      <th>21352</th>\n",
              "      <th>21353</th>\n",
              "      <th>21354</th>\n",
              "      <th>21355</th>\n",
              "      <th>21356</th>\n",
              "      <th>21358</th>\n",
              "      <th>21359</th>\n",
              "      <th>21360</th>\n",
              "      <th>21361</th>\n",
              "      <th>21362</th>\n",
              "      <th>21363</th>\n",
              "      <th>21365</th>\n",
              "      <th>21367</th>\n",
              "      <th>21368</th>\n",
              "      <th>21371</th>\n",
              "      <th>21372</th>\n",
              "      <th>21373</th>\n",
              "      <th>21374</th>\n",
              "      <th>21375</th>\n",
              "      <th>21376</th>\n",
              "      <th>21377</th>\n",
              "      <th>21378</th>\n",
              "      <th>21381</th>\n",
              "      <th>21382</th>\n",
              "      <th>21383</th>\n",
              "      <th>21385</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20019</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20020</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20021</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20022</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20023</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20024 rows × 13456 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d7aeb078-0cb3-43f4-85dd-9fcb17f44f41')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d7aeb078-0cb3-43f4-85dd-9fcb17f44f41 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d7aeb078-0cb3-43f4-85dd-9fcb17f44f41');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "y      1      3      4      5      6      ...  21378  21381  21382  21383  21385\n",
              "x                                         ...                                   \n",
              "0        NaN    NaN    NaN    NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN\n",
              "1        NaN    NaN    NaN    NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN\n",
              "2        NaN    NaN    NaN    NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN\n",
              "3        NaN    NaN    NaN    NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN\n",
              "4        NaN    NaN    NaN    NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN\n",
              "...      ...    ...    ...    ...    ...  ...    ...    ...    ...    ...    ...\n",
              "20019    NaN    NaN    NaN    NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN\n",
              "20020    NaN    NaN    NaN    NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN\n",
              "20021    NaN    NaN    NaN    NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN\n",
              "20022    NaN    NaN    NaN    NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN\n",
              "20023    NaN    NaN    NaN    NaN    NaN  ...    NaN    NaN    NaN    NaN    0.0\n",
              "\n",
              "[20024 rows x 13456 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_mat.loc[0,741]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMN3Qtmt62Ra",
        "outputId": "1adf4759-bebe-4699-bb71-a95a6e984248"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_mat.loc[0,17045]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyhASax58cre",
        "outputId": "6b783da4-d51d-44ea-eae5-0fa3563cc23d"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nan"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_np = train_mat.to_numpy(na_value=0.)\n",
        "train_np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNotgTGg8lD_",
        "outputId": "aad4f8e9-7d94-47ed-fc0e-d2d70a8200ae"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_np.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1Ypm8zW9ny6",
        "outputId": "1fb77a21-1c27-4b88-b7a7-eacf4e016c78"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20024, 13456)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_np[0][[train_np[0] != 0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74In2i5w8yYh",
        "outputId": "f9658817-53e4-4b32-8b33-e38176d3efe8"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  1., 189.,   1.,   3.,   2.,  22.,   2.,   5.,   4.,   8.,   1.,\n",
              "         3.,   1.,   2.,   1.,  10.,   1.,   3.])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## k-means"
      ],
      "metadata": {
        "id": "KT48bi4r9PAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = KMeans(n_clusters=100, max_iter=100_000)"
      ],
      "metadata": {
        "id": "th14CT4k9Qc3"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(train_np)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BN4RGmg49iM7",
        "outputId": "af110ad9-5bcd-4d57-ab9f-2692653f2ee7"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(max_iter=100000, n_clusters=100)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_pred = clf.predict(train_np)\n",
        "train_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bF309v-B-7ye",
        "outputId": "84b33510-c2df-454f-c0ac-576934a89b01"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([67, 30, 30, ..., 30, 30, 30], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_pred_pd = pd.Series(train_pred)\n",
        "train_pred_pd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v523c4-Q_T2Z",
        "outputId": "8215518b-3f21-4d2e-a018-360cef1729dc"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        67\n",
              "1        30\n",
              "2        30\n",
              "3        30\n",
              "4        30\n",
              "         ..\n",
              "20019    30\n",
              "20020    30\n",
              "20021    30\n",
              "20022    30\n",
              "20023    30\n",
              "Length: 20024, dtype: int32"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
        "  print(train_pred_pd.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QPIE4o7_4o8",
        "outputId": "cb346d90-58e1-456d-bb88-d21862bfaf71"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30    18704\n",
            "67      708\n",
            "38       92\n",
            "45       80\n",
            "0        62\n",
            "58       28\n",
            "3        26\n",
            "39       25\n",
            "40       23\n",
            "90       19\n",
            "28       18\n",
            "96       17\n",
            "44       15\n",
            "65       14\n",
            "23       11\n",
            "50        9\n",
            "10        9\n",
            "73        9\n",
            "77        9\n",
            "64        8\n",
            "91        8\n",
            "81        7\n",
            "94        5\n",
            "8         5\n",
            "37        5\n",
            "71        4\n",
            "19        4\n",
            "86        4\n",
            "79        3\n",
            "83        3\n",
            "95        3\n",
            "31        3\n",
            "62        3\n",
            "92        2\n",
            "54        2\n",
            "20        2\n",
            "4         2\n",
            "99        2\n",
            "63        2\n",
            "82        2\n",
            "47        2\n",
            "66        2\n",
            "13        2\n",
            "85        2\n",
            "98        2\n",
            "22        2\n",
            "2         2\n",
            "74        1\n",
            "46        1\n",
            "51        1\n",
            "14        1\n",
            "93        1\n",
            "35        1\n",
            "78        1\n",
            "52        1\n",
            "34        1\n",
            "18        1\n",
            "97        1\n",
            "15        1\n",
            "49        1\n",
            "33        1\n",
            "17        1\n",
            "1         1\n",
            "80        1\n",
            "48        1\n",
            "32        1\n",
            "16        1\n",
            "36        1\n",
            "5         1\n",
            "68        1\n",
            "24        1\n",
            "42        1\n",
            "26        1\n",
            "27        1\n",
            "89        1\n",
            "43        1\n",
            "57        1\n",
            "41        1\n",
            "25        1\n",
            "9         1\n",
            "88        1\n",
            "72        1\n",
            "56        1\n",
            "59        1\n",
            "75        1\n",
            "84        1\n",
            "87        1\n",
            "12        1\n",
            "60        1\n",
            "76        1\n",
            "7         1\n",
            "70        1\n",
            "29        1\n",
            "6         1\n",
            "69        1\n",
            "53        1\n",
            "61        1\n",
            "21        1\n",
            "11        1\n",
            "55        1\n",
            "dtype: int64\n"
          ]
        }
      ]
    }
  ]
}